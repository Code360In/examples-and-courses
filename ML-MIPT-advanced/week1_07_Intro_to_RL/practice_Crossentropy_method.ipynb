{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g093K7GbpLjN"
   },
   "source": [
    "# Crossentropy method\n",
    "_Reference: based on Practical RL_ [week01](https://github.com/yandexdataschool/Practical_RL/tree/master/week01_intro)\n",
    "\n",
    "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBKhjK7wpLjO",
    "outputId": "5e4b2e4a-5310-437f-d6de-84cf664198be"
   },
   "outputs": [],
   "source": [
    "# In Google Colab, uncomment this:\n",
    "# !wget https://bit.ly/2FMJP5K -O setup.py && bash setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_nV8PONpLjU",
    "outputId": "78c71a38-43e2-4d31-beff-a9ee5b00a8b5"
   },
   "outputs": [],
   "source": [
    "# !pip install gym==0.15.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhGOoy_ApLjY",
    "outputId": "a2dfe9e8-0cb9-4add-c7b1-3301b9822eca"
   },
   "outputs": [],
   "source": [
    "# XVFB will be launched if you run on a server\n",
    "# import os\n",
    "# if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "#     !bash ../xvfb start\n",
    "#     %env DISPLAY = : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpAEpo7KpLjd",
    "outputId": "9604330f-d1c7-4b26-aa86-9c80c91ccf5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :\u001b[43mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2ONiOdwpLji",
    "outputId": "3157a649-0c8d-45d3-b6f8-93424ea261c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_states=500, n_actions=6\n"
     ]
    }
   ],
   "source": [
    "n_states = env.observation_space.n\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEbcNcxFpLjo"
   },
   "source": [
    "# Create stochastic policy\n",
    "\n",
    "This time our policy should be a probability distribution.\n",
    "\n",
    "```policy[s,a] = P(take action a | in state s)```\n",
    "\n",
    "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
    "\n",
    "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9oFxfSsypLjp"
   },
   "outputs": [],
   "source": [
    "policy = np.full((n_states, n_actions), 1./n_actions) # <your code here! Create an array to store action probabilities>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Myyitj42pLju"
   },
   "outputs": [],
   "source": [
    "assert type(policy) in (np.ndarray, np.matrix)\n",
    "assert np.allclose(policy, 1./n_actions)\n",
    "assert np.allclose(np.sum(policy, axis=1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wroPVhUepLj0",
    "outputId": "c59aeb9a-694d-40f9-de2f-342284ec580d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       ...,\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZRw-nNKpLj6"
   },
   "source": [
    "# Play the game\n",
    "\n",
    "Just like before, but we also record all states and actions we took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QRGWE-fapLj7"
   },
   "outputs": [],
   "source": [
    "def generate_session(policy, t_max=int(10**4)):\n",
    "    \"\"\"\n",
    "    Play game until end or for t_max ticks.\n",
    "    :param policy: an array of shape [n_states,n_actions] with action probabilities\n",
    "    :returns: list of states, list of actions and sum of rewards\n",
    "    \"\"\"\n",
    "    states, actions = [], []\n",
    "    total_reward = 0.\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=policy[s]) # <sample action from policy(hint: use np.random.choice) >\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # Record state, action and add up reward to states,actions and total_reward accordingly.\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bHH9IXzFpLj_"
   },
   "outputs": [],
   "source": [
    "s, a, r = generate_session(policy)\n",
    "assert type(s) == type(a) == list\n",
    "assert len(s) == len(a)\n",
    "assert type(r) in [float, np.float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "YMTb2A49pLkD",
    "outputId": "80d09727-3f37-4d35-a1d2-6435c8be0cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f38ff83b9a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's see the initial reward distribution\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
    "\n",
    "plt.hist(sample_rewards, bins=20)\n",
    "plt.vlines([np.percentile(sample_rewards, 50)], [0], [100], label=\"50'th percentile\", color='green')\n",
    "plt.vlines([np.percentile(sample_rewards, 90)], [0], [100], label=\"90'th percentile\", color='red')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRt1zhihpLkH",
    "outputId": "ebfc65d4-80f1-4b2b-e964-fa41ac5286e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-686.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(sample_rewards, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIqUwCMBpLkL"
   },
   "source": [
    "### Crossentropy method steps (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eIYfF7GQpLkM"
   },
   "outputs": [],
   "source": [
    "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
    "    \"\"\"\n",
    "    Select states and actions from games that have rewards >= percentile\n",
    "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
    "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
    "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
    "\n",
    "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
    "\n",
    "    Please return elite states and actions in their original order \n",
    "    [i.e. sorted by session number and timestep within session]\n",
    "\n",
    "    If you are confused, see examples below. Please don't assume that states are integers\n",
    "    (they will become different later).\n",
    "    \"\"\"\n",
    "\n",
    "    reward_threshold =  np.percentile(rewards_batch, percentile) # <Compute minimum reward for elite sessions. Hint: use np.percentile >\n",
    " \n",
    "    elite_states = [] # <your code here >\n",
    "    elite_actions = [] # <your code here >\n",
    "\n",
    "    for states, action, reward in zip(states_batch, actions_batch, rewards_batch):\n",
    "        if reward >= reward_threshold:\n",
    "            elite_states += states\n",
    "            elite_actions += action\n",
    "\n",
    "    return elite_states, elite_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OZEnFO-pLkS",
    "outputId": "7bbaa3f2-0765-4432-a461-1e9f46bd759d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "states_batch = [\n",
    "    [1, 2, 3],     # game1\n",
    "    [4, 2, 0, 2],  # game2\n",
    "    [3, 1],        # game3\n",
    "]\n",
    "\n",
    "actions_batch = [\n",
    "    [0, 2, 4],     # game1\n",
    "    [3, 2, 0, 1],  # game2\n",
    "    [3, 3],        # game3\n",
    "]\n",
    "rewards_batch = [\n",
    "    3,  # game1\n",
    "    4,  # game2\n",
    "    5,  # game3\n",
    "]\n",
    "\n",
    "test_result_0 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
    "test_result_40 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
    "test_result_90 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
    "test_result_100 = select_elites(\n",
    "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
    "\n",
    "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
    "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
    "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
    "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
    "    \"For percentile 30 you should only select states/actions from two first\"\n",
    "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
    "    np.all(test_result_90[1] == [3, 3]),\\\n",
    "    \"For percentile 90 you should only select states/actions from one game\"\n",
    "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
    "    np.all(test_result_100[1] == [3, 3]),\\\n",
    "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "SeZIyU8DpLkX"
   },
   "outputs": [],
   "source": [
    "def update_policy(elite_states, elite_actions):\n",
    "    \"\"\"\n",
    "    Given old policy and a list of elite states/actions from select_elites,\n",
    "    return new updated policy where each action probability is proportional to\n",
    "\n",
    "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
    "\n",
    "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
    "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
    "\n",
    "    :param elite_states: 1D list of states from elite sessions\n",
    "    :param elite_actions: 1D list of actions from elite sessions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    new_policy = np.zeros([n_states, n_actions])\n",
    "\n",
    "    for idx in range(len(elite_states)):\n",
    "        new_policy[elite_states[idx], elite_actions[idx]] += 1\n",
    "\n",
    "    never_visited_states = new_policy.sum(axis=1) == 0\n",
    "    new_policy[never_visited_states] = 1\n",
    "\n",
    "    new_policy /= new_policy.sum(axis=1)[:, None]\n",
    "    \n",
    "#     <Your code here: update probabilities for actions given elite states & actions >\n",
    "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
    "\n",
    "    return new_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DY6v4RpMpLkc",
    "outputId": "7399da26-3fbe-4fc5-8b62-0e5474f07aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "elite_states = [1, 2, 3, 4, 2, 0, 2, 3, 1]\n",
    "elite_actions = [0, 2, 4, 3, 2, 0, 1, 3, 3]\n",
    "\n",
    "new_policy = update_policy(elite_states, elite_actions)\n",
    "\n",
    "assert np.isfinite(new_policy).all(\n",
    "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
    "assert np.all(\n",
    "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
    "assert np.allclose(new_policy.sum(\n",
    "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
    "reference_answer = np.array([\n",
    "    [1.,  0.,  0.,  0.,  0.],\n",
    "    [0.5,  0.,  0.,  0.5,  0.],\n",
    "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
    "    [0.,  0.,  0.,  0.5,  0.5]])\n",
    "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
    "print(\"Ok!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTMc6UnvpLkg"
   },
   "source": [
    "# Training loop\n",
    "Generate sessions, select N best and fit to those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "syWv17eSpLkh"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
    "    \"\"\"\n",
    "    A convenience function that displays training progress. \n",
    "    No cool math here, just charts.\n",
    "    \"\"\"\n",
    "\n",
    "    mean_reward = np.mean(rewards_batch)\n",
    "    threshold = np.percentile(rewards_batch, percentile)\n",
    "    log.append([mean_reward, threshold])\n",
    "\n",
    "    clear_output(True)\n",
    "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
    "    plt.figure(figsize=[8, 4])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
    "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(rewards_batch, range=reward_range)\n",
    "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
    "               [0], [100], label=\"percentile\", color='red')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7Wnqib6ypLkl"
   },
   "outputs": [],
   "source": [
    "# reset policy just in case\n",
    "policy = np.ones([n_states, n_actions]) / n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCbxVNWUpLkp",
    "outputId": "b82e4b37-d40f-4dc1-90fc-97e3267b18dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       ...,\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "id": "KsfocUiSpLks",
    "outputId": "0c744dea-0236-4c4c-8abc-b70ade67869d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean reward = -35.296, threshold=6.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_sessions = 250  # sample this many sessions\n",
    "percentile = 50  # take this percent of session with highest rewards\n",
    "learning_rate = 0.5  # add this thing to all counts for stability\n",
    "\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # if (i+1) % 3 == 0:\n",
    "    #     percentile += 1\n",
    "\n",
    "    sessions = [generate_session(policy) for _ in range(n_sessions)] # [ < generate a list of n_sessions new sessions > ]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile) # <select elite states/actions >\n",
    "\n",
    "    new_policy = update_policy(elite_states, elite_actions) # <compute new policy >\n",
    "\n",
    "    policy = learning_rate*new_policy + (1-learning_rate)*policy\n",
    "\n",
    "    # display results on chart\n",
    "    show_progress(rewards_batch, log, percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dEx99uJpLkx"
   },
   "source": [
    "# Digging deeper: approximate crossentropy with neural nets\n",
    "\n",
    "![img](https://tip.duke.edu/independent_learning/greek/lesson/digging_deeper_final.jpg)\n",
    "\n",
    "In this section we will train a neural network policy for continuous state space game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "yiAih6dApLky",
    "outputId": "ab3c9c53-2604-44aa-faeb-529d4bbd9a08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kryvokhyzha/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f38ff5e0ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if you see \"<classname> has no attribute .env\", remove .env or update gym\n",
    "env = gym.make(\"CartPole-v0\").env\n",
    "\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hvjXXUspLk2",
    "outputId": "6fa629ff-b81a-4401-d61f-890a3a6e99ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AR2ALp0ypLk6",
    "outputId": "c9af1bd9-4052-49cf-e7db-e50d3b6d0be2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kryvokhyzha/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(20, 20), max_iter=1,\n",
       "              warm_start=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create agent\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "agent = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation='tanh',\n",
    "    warm_start=True,  # keep progress between .fit(...) calls\n",
    "    max_iter=1,  # make only 1 iteration on each .fit(...)\n",
    ")\n",
    "# initialize agent to the dimension of state an amount of actions\n",
    "agent.fit([env.reset()]*n_actions, range(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYzlmnlK3a1z",
    "outputId": "e1eedbc2-8769-447d-8f05-8126f34fec6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3697289, 0.6302711]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.predict_proba([env.reset()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "L_jnttlNpLk_"
   },
   "outputs": [],
   "source": [
    "def generate_session(t_max=100):\n",
    "\n",
    "    states, actions = [], []\n",
    "    total_reward = 0\n",
    "\n",
    "    s = env.reset()\n",
    "\n",
    "    for t in range(t_max):\n",
    "\n",
    "        # predict array of action probabilities\n",
    "        probs = agent.predict_proba([s])[0]\n",
    "\n",
    "        a = np.random.choice(np.arange(n_actions), p=probs) # <sample action with such probabilities >\n",
    "\n",
    "        new_s, r, done, info = env.step(a)\n",
    "\n",
    "        # record sessions like you did before\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        total_reward += r\n",
    "\n",
    "        s = new_s\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "NoMUFv7bpLlE",
    "outputId": "f3e42d44-4d35-488a-b178-b208c1afad1e"
   },
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0e63bb830dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# < generate a list of n_sessions new sessions > ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-0e63bb830dbe>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# generate new sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_sessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# < generate a list of n_sessions new sessions > ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstates_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-17f919e5b8e1>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over."
     ]
    }
   ],
   "source": [
    "n_sessions = 100\n",
    "percentile = 70\n",
    "log = []\n",
    "\n",
    "for i in range(100):\n",
    "    # generate new sessions\n",
    "    sessions = [generate_session() for _ in range(n_sessions)] # < generate a list of n_sessions new sessions > ]\n",
    "\n",
    "    states_batch, actions_batch, rewards_batch = map(np.array, zip(*sessions))\n",
    "\n",
    "    elite_states, elite_actions = select_elites(states_batch, actions_batch, rewards_batch, percentile=percentile) # <select elite actions just like before>\n",
    "    \n",
    "    agent.fit(elite_states, elite_actions) # <fit agent to predict elite_actions(y) from elite_states(X)>\n",
    "\n",
    "    if max(rewards_batch) > min(rewards_batch):\n",
    "        show_progress(rewards_batch, log, percentile, reward_range=[0, np.max(rewards_batch)])\n",
    "\n",
    "    if np.mean(rewards_batch) > 190:\n",
    "        print(\"You Win! You may stop training now via KeyboardInterrupt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zcbj0gSnpLlI"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "3nhjL3GdpLlI",
    "outputId": "c161f10f-04a2-4953-eb3b-421b8c61e574"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kryvokhyzha/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-411c2b6c5dea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-411c2b6c5dea>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m                            directory=\"videos\", force=True)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msessions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-70d63bebc525>\u001b[0m in \u001b[0;36mgenerate_session\u001b[0;34m(t_max)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for CartPole-v0, you cannot call reset() unless the episode is over."
     ]
    }
   ],
   "source": [
    "# record sessions\n",
    "import gym.wrappers\n",
    "env = gym.wrappers.Monitor(gym.make(\"CartPole-v0\"),\n",
    "                           directory=\"videos\", force=True)\n",
    "\n",
    "sessions = [generate_session() for _ in range(100)]\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "hW8UrBPdpLlN",
    "outputId": "e3d2c8f1-6471-4fb1-dfde-f8eb63ce1e4c"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5eb76ceca868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;34m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{}\"\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"video/mp4\"\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \"\"\".format(\"./videos/\"+video_names[-3]))  # this may or may not be _last_ video. Try other indices\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(\n",
    "    filter(lambda s: s.endswith(\".mp4\"), os.listdir(\"./videos/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./videos/\"+video_names[-3]))  # this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmdh2uxYpLlQ"
   },
   "source": [
    "## Bonus area I\n",
    "\n",
    "### Tabular crossentropy method\n",
    "\n",
    "You may have noticed that the taxi problem quickly converges from -100 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
    "\n",
    "### Tasks\n",
    "- __1.1__ (1 pts) Find out how the algorithm performance changes if you use a different `percentile` and/or `n_sessions`.\n",
    "- __1.2__ (2 pts) Tune the algorithm to end up with positive average score.\n",
    "\n",
    "It's okay to modify the existing code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRqb020XpLlR"
   },
   "source": [
    "```<Describe what you did here.  Preferably with plot/report to support it.>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLu2ooBlpLlW"
   },
   "source": [
    "## Bonus area II\n",
    "\n",
    "### Deep crossentropy method\n",
    "\n",
    "By this moment you should have got enough score on [CartPole-v0](https://gym.openai.com/envs/CartPole-v0) to consider it solved (see the link). It's time to try something harder.\n",
    "\n",
    "* if you have any trouble with CartPole-v0 and feel stuck, feel free to ask us or your peers for help.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "* __2.1__ (3 pts) Pick one of environments: MountainCar-v0 or LunarLander-v2.\n",
    "  * For MountainCar, get average reward of __at least -150__\n",
    "  * For LunarLander, get average reward of __at least +50__\n",
    "\n",
    "See the tips section below, it's kinda important.\n",
    "__Note:__ If your agent is below the target score, you'll still get most of the points depending on the result, so don't be afraid to submit it.\n",
    "  \n",
    "  \n",
    "* __2.2__ (bonus: 4++ pt) Devise a way to speed up training at least 2x against the default version\n",
    "  * Obvious improvement: use [joblib](https://www.google.com/search?client=ubuntu&channel=fs&q=joblib&ie=utf-8&oe=utf-8)\n",
    "  * Try re-using samples from 3-5 last iterations when computing threshold and training\n",
    "  * Experiment with amount of training iterations and learning rate of the neural network (see params)\n",
    "  * __Please list what you did in anytask submission form__\n",
    "  \n",
    "  \n",
    "### Tips\n",
    "* Gym page: [MountainCar](https://gym.openai.com/envs/MountainCar-v0), [LunarLander](https://gym.openai.com/envs/LunarLander-v2)\n",
    "* Sessions for MountainCar may last for 10k+ ticks. Make sure ```t_max``` param is at least 10k.\n",
    " * Also it may be a good idea to cut rewards via \">\" and not \">=\". If 90% of your sessions get reward of -10k and 20% are better, than if you use percentile 20% as threshold, R >= threshold __fails cut off bad sessions__ whule R > threshold works alright.\n",
    "* _issue with gym_: Some versions of gym limit game time by 200 ticks. This will prevent cem training in most cases. Make sure your agent is able to play for the specified __t_max__, and if it isn't, try `env = gym.make(\"MountainCar-v0\").env` or otherwise get rid of TimeLimit wrapper.\n",
    "* If you use old _swig_ lib for LunarLander-v2, you may get an error. See this [issue](https://github.com/openai/gym/issues/100) for solution.\n",
    "* If it won't train it's a good idea to plot reward distribution and record sessions: they may give you some clue. If they don't, call course staff :)\n",
    "* 20-neuron network is probably not enough, feel free to experiment.\n",
    "\n",
    "You may find the following snippet useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMjrcpIFpLlW"
   },
   "outputs": [],
   "source": [
    "def visualize_mountain_car(env, agent):\n",
    "    xs = np.linspace(env.min_position, env.max_position, 100)\n",
    "    vs = np.linspace(-env.max_speed, env.max_speed, 100)\n",
    "    grid = np.dstack(np.meshgrid(xs, vs)).transpose(1, 0, 2)\n",
    "    grid_flat = grid.reshape(len(xs) * len(vs), 2)\n",
    "    probs = agent.predict_proba(grid_flat).reshape(len(xs), len(vs), 3)\n",
    "    return probs\n",
    "\n",
    "plt.imshow(visualize_mountain_car(env, agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg852zoBpLlZ"
   },
   "source": [
    "### More bonus tasks\n",
    "\n",
    "* __2.3 bonus__ Try to find a network architecture and training params that solve __both__ environments above (_Points depend on implementation. If you attempted this task, please mention it in anytask submission._)\n",
    "\n",
    "* __2.4 bonus__ Solve continuous action space task with `MLPRegressor` or similar.\n",
    "  * Start with [\"Pendulum-v0\"](https://github.com/openai/gym/wiki/Pendulum-v0).\n",
    "  * Since your agent only predicts the \"expected\" action, you will have to add noise to ensure exploration.\n",
    "  * [MountainCarContinuous-v0](https://gym.openai.com/envs/MountainCarContinuous-v0), [LunarLanderContinuous-v2](https://gym.openai.com/envs/LunarLanderContinuous-v2) \n",
    "  * 4 points for solving. Slightly less for getting some results below solution threshold. Note that discrete and continuous environments may have slightly different rules aside from action spaces.\n",
    "\n",
    "\n",
    "If you're still feeling unchallenged, consider the project (see other notebook in this folder)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of practice_Crossentropy_method.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
