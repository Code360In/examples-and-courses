{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deloit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgHP_r9YUTEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzQpsxs0UXdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ee7f1411-ecf7-4b4f-9b44-a1eca8c66fbf"
      },
      "source": [
        "!pip install pandas==0.21.1"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==0.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e1/6c514df670b887c77838ab856f57783c07e8760f2e3d5939203a39735e0e/pandas-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
            "\u001b[K     |████████████████████████████████| 26.2MB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.21.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.21.1) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.21.1) (1.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas==0.21.1) (1.12.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.10.0 has requirement pandas>=0.22.0, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: featuretools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.6 has requirement pandas>=0.23.4, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 1.0.3\n",
            "    Uninstalling pandas-1.0.3:\n",
            "      Successfully uninstalled pandas-1.0.3\n",
            "Successfully installed pandas-0.21.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkx7DnH9U1fV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc6U_PMtRoeS",
        "colab_type": "text"
      },
      "source": [
        "# Module importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYTVLnlRRsV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igq2e9enN1MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from multiprocessing import Pool"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHr43ME3N4V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibcBXJ8jPfW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzrRIiiOZ1iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwTZPJpntVqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq2VwYfQ6m_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IhpVNU2RIvc",
        "colab_type": "text"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b1qcYk6O7jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "2608aa21-5994-4def-fceb-65b688e7cab9"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"kryvokhyzha\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"b30f0451d14f9a4f8a939d2fbadf03e8\" # key from the json file\n",
        "!kaggle competitions download -c company-acceptance-prediction # api copied from kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train_df.pkl.zip to /content\n",
            " 95% 171M/180M [00:01<00:00, 112MB/s]\n",
            "100% 180M/180M [00:01<00:00, 129MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/167k [00:00<?, ?B/s]\n",
            "100% 167k/167k [00:00<00:00, 150MB/s]\n",
            "Downloading test_df.pkl.zip to /content\n",
            " 79% 65.0M/82.3M [00:00<00:00, 72.3MB/s]\n",
            "100% 82.3M/82.3M [00:00<00:00, 121MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5ET6VjFRQb5",
        "colab_type": "text"
      },
      "source": [
        "# Data serialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLUZ1YkxPRtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_pickle('train_df.pkl.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgiRC140RmsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_pickle('test_df.pkl.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1UmNpwoXOw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "73fd8665-d23e-490d-b432-d77dfb9feab3"
      },
      "source": [
        "test_df.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>html</th>\n",
              "      <th>text</th>\n",
              "      <th>keywords</th>\n",
              "      <th>accepted_function</th>\n",
              "      <th>rejected_function</th>\n",
              "      <th>accepted_product</th>\n",
              "      <th>rejected_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>071c2e15-5fd0-4e7d-b78d-26b7c34491e1</td>\n",
              "      <td>[b'&lt;!DOCTYPE html&gt;\\r\\n&lt;html id=\"ctl00_htmlMast...</td>\n",
              "      <td>[We use cookies to tailor our service and ensu...</td>\n",
              "      <td>[technologies, descriptive, mapping, learning,...</td>\n",
              "      <td>IT support, IT managed services, IT integratio...</td>\n",
              "      <td>manufacture, production, processing, distribut...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e534df73-b385-4a12-8368-38992d3af7d3</td>\n",
              "      <td>[b'\\n&lt;!DOCTYPE html&gt;\\n\\n&lt;html lang=\"en-US\"&gt;\\n\\...</td>\n",
              "      <td>[About us\\nAbout Powernet\\nPartnerships\\nCusto...</td>\n",
              "      <td>[outsourcing, projects, IT, sensors, convergen...</td>\n",
              "      <td>software development, database development, sy...</td>\n",
              "      <td>wholesale, distribution, retail selling, manuf...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4e38c9ff-bffe-4251-b2b2-94777c7344fe</td>\n",
              "      <td>[b'&lt;!--\\n.----------------.  .----------------...</td>\n",
              "      <td>[Work\\nApproach\\nPeople\\nValues\\nBlog\\nCareers...</td>\n",
              "      <td>[Inventing, products, risk, development, servi...</td>\n",
              "      <td>general accounting, auditing, book keeping act...</td>\n",
              "      <td>manufacture, production, processing, distribut...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a7f8870c-30f8-4851-8f8b-4c16942b397f</td>\n",
              "      <td>[b'&lt;!DOCTYPE html&gt;\\n&lt;!--[if lt IE 7]&gt;&lt;html cla...</td>\n",
              "      <td>[Menu\\nMenu\\nSupport\\nInfrastructure\\nColocati...</td>\n",
              "      <td>[low, chain, portfolio, services, Procurement,...</td>\n",
              "      <td>Investment research and information services, ...</td>\n",
              "      <td>Construction, production and supply, Advertisi...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c062f411-ae3e-486a-9cba-2267889adb2b</td>\n",
              "      <td>[b'&lt;!DOCTYPE html&gt;&lt;html lang=\"en-US\"&gt;&lt;head&gt;&lt;me...</td>\n",
              "      <td>[Français (French)\\nEnglish (English)\\n日本語 (Ja...</td>\n",
              "      <td>[recruitment, producing, Evaluation, Payroll, ...</td>\n",
              "      <td>general accounting, auditing, book keeping act...</td>\n",
              "      <td>manufacture, production, processing, distribut...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  ... rejected_product\n",
              "0  071c2e15-5fd0-4e7d-b78d-26b7c34491e1  ...                 \n",
              "1  e534df73-b385-4a12-8368-38992d3af7d3  ...                 \n",
              "2  4e38c9ff-bffe-4251-b2b2-94777c7344fe  ...                 \n",
              "3  a7f8870c-30f8-4851-8f8b-4c16942b397f  ...                 \n",
              "4  c062f411-ae3e-486a-9cba-2267889adb2b  ...                 \n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rekFGiJho6eX",
        "colab_type": "text"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsBq63L-49CC",
        "colab_type": "text"
      },
      "source": [
        "## Dropping byte-like parts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ccvhDYx8s5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# :("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwTD7L1ws4Gg",
        "colab_type": "text"
      },
      "source": [
        "## Extract comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucdNFooW6hFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# :("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHtTZtEY6hjC",
        "colab_type": "text"
      },
      "source": [
        "## Extract meta information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7MDtqGPMd-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['Title'] = np.nan\n",
        "train_df['Keyword'] = np.nan\n",
        "train_df['Locale'] = np.nan\n",
        "train_df['Description'] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8da8e999-8d11-481f-aa00-a3cde5495824",
        "id": "UebfmWQqRRvG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for idx, pages in tqdm.tqdm(enumerate(train_df.html)):\n",
        "  title_res = []\n",
        "  keywords_res = []\n",
        "  locale_res = []\n",
        "  description_res = []\n",
        "  for page in pages:\n",
        "    soup = BeautifulSoup(page, \"lxml\")  \n",
        "\n",
        "    res = ''\n",
        "    for tag in soup.find_all(\"meta\", property='og:title'):\n",
        "      try:\n",
        "        if tag['content'] not in (', ', '', ',', ' ', '.'):\n",
        "          res += tag['content'].strip() + ' '\n",
        "      except:\n",
        "        pass\n",
        "    if res != '':\n",
        "      title_res.append(res.strip()) \n",
        "\n",
        "    res = ''\n",
        "    for tag in soup.find_all(\"meta\", attrs={'name':'keywords'}):\n",
        "      try:\n",
        "        if tag['content'] not in (', ', '', ',', ' ', '.'):\n",
        "          res += tag['content'].strip() + ' '\n",
        "      except:\n",
        "        pass\n",
        "    if res != '':\n",
        "      keywords_res.append(res.strip()) \n",
        "\n",
        "    res = ''\n",
        "    for tag in soup.find_all(\"meta\", property='og:locale'):\n",
        "      try:\n",
        "        if tag['content'] not in (', ', '', ',', ' ', '.'):\n",
        "          res += tag['content'].strip() + ' ' \n",
        "      except:\n",
        "        pass\n",
        "    if res != '':\n",
        "      locale_res.append(res.strip()) \n",
        "\n",
        "    res = ''\n",
        "    for tag in soup.find_all(\"meta\", attrs={'name':'description'}):\n",
        "      try:\n",
        "        if tag['content'] not in (', ', '', ',', ' ', '.'):\n",
        "          res += tag['content'].strip() + ' '\n",
        "      except:\n",
        "        pass\n",
        "    if res != '':\n",
        "      description_res.append(res.strip()) \n",
        "\n",
        "\n",
        "  train_df.loc[idx, 'Title'] = str(title_res) if title_res != [] else np.nan\n",
        "  train_df.loc[idx, 'Keyword'] = str(keywords_res) if keywords_res != [] else np.nan\n",
        "  train_df.loc[idx, 'Locale'] = str(locale_res) if locale_res != [] else np.nan\n",
        "  train_df.loc[idx, 'Description'] = str(description_res) if description_res != [] else np.nan\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15515it [35:07,  7.36it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKXDJRhpu_2n",
        "colab_type": "text"
      },
      "source": [
        "### Locale preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DROoCh-_u-01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sl - seldom, ot - other\n",
        "train_df.Locale = train_df.Locale.fillna('[\"ot').apply(lambda x: x[2:4]).map({'ot': 'ot', 'en': 'en', 'ja': 'ja', 'pl':'pl',\n",
        "                                                                              'es': 'sl', 'de': 'sl', 'it': 'sl',\n",
        "                                                                              'fr': 'sl', 'bg': 'sl', 'zh': 'sl',\n",
        "                                                                              'sv': 'sl','nl': 'sl','fi': 'sl',\n",
        "                                                                              'nb': 'sl'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2g47wEJyGjI",
        "colab_type": "text"
      },
      "source": [
        "### Title preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVuKHWuCyKbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Title = train_df.Title.fillna('without_title').apply(lambda x: ' '.join(list(set(re.sub(r'[^\\w\\s\\d,\\[\\]]+', '', x).strip('][').lower().split(', ')))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V76q1xP40Vbc",
        "colab_type": "text"
      },
      "source": [
        "### Keyword preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euABvgOzyKYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Keyword = train_df.Keyword.fillna('without_keyword').apply(lambda x: ' '.join(list(set(re.sub(r'[^\\w\\s\\d,\\[\\]]+', '', x).strip('][').lower().split(', ')))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GS0s_ki0kcH",
        "colab_type": "text"
      },
      "source": [
        "### Description preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCxiwGXNK6K3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "aa2c0cbe-73b1-44fb-cfaa-a7ceca2bf4d2"
      },
      "source": [
        "train_df.Description[95]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"['RAFFIN MEDICAL is a manufacturer and a distributor of single-use medical devices for health care professionals, since 1914.', 'Since 1914, Raffin Medical has been developing, manufacturing and commercializing single use medical devices for health care professionals']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tuggORd0kKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Description = train_df.Description.fillna('without_description').apply(lambda x: ' '.join(list(set(re.sub(r'[^\\w\\s\\d,\\[\\]]+', '', x).strip('][').lower().split(', ')))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REQWriG9I56p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Description = train_df.Description.apply(lambda x: x if re.sub(r'[a-zA-Z0-9\\s\\-_]+', '', x.strip()) == '' else 'wrong_description')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fgKu_h8M9Z3",
        "colab_type": "text"
      },
      "source": [
        "## Keywords (model base) preproccesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sQI8ORUMUV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.keywords = train_df.keywords.apply(lambda x: [re.sub(r'[^\\w\\s\\d]+', ' ', i).lower() for i in x] if x != [] else ['empty_keyword_list'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTeWSbxOmWe",
        "colab_type": "text"
      },
      "source": [
        "## Accepted/rejected preproccesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj491-jfOpCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.accepted_function = train_df.accepted_function.apply(lambda x: re.sub(r'[^\\w\\s\\d,]+', ' ', x).lower() if x != '' else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7yW-9ZrOz8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.rejected_function = train_df.rejected_function.apply(lambda x: re.sub(r'[^\\w\\s\\d,]+', ' ', x).lower() if x != '' else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hitfWm-IPbRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.accepted_product = train_df.accepted_product.apply(lambda x: re.sub(r'[^\\w\\s\\d,]+', ' ', x).lower() if x != '' else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kD0JTS_PbH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.rejected_product = train_df.rejected_product.apply(lambda x: re.sub(r'[^\\w\\s\\d,]+', ' ', x).lower() if x != '' else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaHJt_3IBT_7",
        "colab_type": "text"
      },
      "source": [
        "## Replace NaN like values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDvcKy-T4Uf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.replace(['', '_nan_'], [np.nan, np.nan])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qCswsO9Qcix",
        "colab_type": "text"
      },
      "source": [
        "## Filling keyword and description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA5gy5--QaGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Keyword = train_df.Keyword.fillna('without_keyword')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQdnJQwQsXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.Description = train_df.Description.fillna('without_description')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL57KCm9pCR8",
        "colab_type": "text"
      },
      "source": [
        "## Combine all texts and html pages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPTUXylEpBEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# :("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l22w7thUW9TI",
        "colab_type": "text"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtCgwzcCavl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "388abb63-731b-4170-bb6e-0f56c5b9f044"
      },
      "source": [
        "print(train_df.text[15][0]) #1439"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This page is being redirected. If it does not load, click https://www.fscables.com/featured_page/antennax--the-ultra-low-loss-coaxial-cable-range.html\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib7jzMMtX3CM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb8304d3-4823-4ddb-f003-beefbca42b08"
      },
      "source": [
        "print(str(train_df.html[2028][0]))"
      ],
      "execution_count": 464,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b\"<br />\\n<b>Fatal error</b>:  Uncaught Error: Call to undefined function mcrypt_create_iv() in /home/forumtna/public_html/system/library/encryption.php:8\\nStack trace:\\n#0 /home/forumtna/public_html/index.php(215): Encryption-&gt;__construct('8751d0dc1cb676e...')\\n#1 {main}\\n  thrown in <b>/home/forumtna/public_html/system/library/encryption.php</b> on line <b>8</b><br />\\n\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6kw6ybdSPLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f7b173e2-3e39-44b2-a523-5c80a51f4c7b"
      },
      "source": [
        "train_df['target'].value_counts() / train_df['target'].value_counts().sum()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.744892\n",
              "2    0.190139\n",
              "0    0.064969\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVvfNOj3oHqY",
        "colab_type": "text"
      },
      "source": [
        "# Feature generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WG79UABT22V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['html_page_cnt'] = train_df.html.apply(lambda x: len(x)).astype(np.int16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9bX-Uu-ZI2P",
        "colab_type": "text"
      },
      "source": [
        "## Mean number of rows in texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzgHeHnlZU55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['text_rows_mean'] = train_df.text.apply(lambda x: np.sum([len(i.split('\\n')) for i in x]) // len(x)).astype(np.int16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnTt-4lualKy",
        "colab_type": "text"
      },
      "source": [
        "## Missing values columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiawjapMboJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['is_mis_accepted_function'] = pd.isnull(train_df.accepted_function).map({True:1, False:0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH8bfz-zccld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['is_mis_rejected_function'] = pd.isnull(train_df.rejected_function).map({True:1, False:0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq5ZnOzQccik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['is_mis_accepted_product'] = pd.isnull(train_df.accepted_product).map({True:1, False:0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDGcdJDxccf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['is_mis_rejected_product'] = pd.isnull(train_df.rejected_product).map({True:1, False:0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHuxHvM0lKoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['is_mis_keyword'] = train_df['keywords'].apply(lambda x: 1 if x == ['empty_keyword_list'] else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXTJ8kY4oU1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.fillna('is_missing')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNU8j4pmdKcA",
        "colab_type": "text"
      },
      "source": [
        "## Redirect feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6FjYpwkoWWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['have_error'] = train_df.text.apply(lambda x: 1 if (('redirected' in x[0].lower() or 'error' in x[0].lower()) and len(x) == 1) else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLUvcJ3ygiG2",
        "colab_type": "text"
      },
      "source": [
        "## Similarity criteria features (in accepted and rejected)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-dtKxcNghti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_f_rej_f_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  accepted_f = set(row.accepted_function.replace(',', '').split(' '))\n",
        "  rejected_f = set(row.rejected_function.replace(',', '').split(' '))\n",
        "  acc_f_rej_f_sim.append(len(accepted_f.intersection(rejected_f)) / len(accepted_f.union(rejected_f)))\n",
        "\n",
        "train_df['acc_f_rej_f_sim'] = acc_f_rej_f_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SAfbvvfghqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_p_rej_p_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  accepted_p = set(row.accepted_product.replace(',', '').split(' '))\n",
        "  rejected_p = set(row.rejected_product.replace(',', '').split(' '))\n",
        "  acc_p_rej_p_sim.append(len(accepted_p.intersection(rejected_p)) / len(accepted_p.union(rejected_p)))\n",
        "\n",
        "train_df['acc_p_rej_p_sim'] = acc_p_rej_p_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhbZv9U5ml-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kwd_acc_p_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  kwd = set(', '.join(row.keywords).replace(',', '').split(' '))\n",
        "  accepted_p = set(row.accepted_product.replace(',', '').split(' '))\n",
        "  kwd_acc_p_sim.append(len(kwd.intersection(accepted_p)) / len(kwd.union(accepted_p)))\n",
        "\n",
        "train_df['kwd_acc_p_sim'] = kwd_acc_p_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umslKveRghnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kwd_rej_p_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  kwd = set(', '.join(row.keywords).replace(',', '').split(' '))\n",
        "  rejected_p = set(row.rejected_product.replace(',', '').split(' '))\n",
        "  kwd_rej_p_sim.append(len(kwd.intersection(rejected_p)) / len(kwd.union(rejected_p)))\n",
        "\n",
        "train_df['kwd_rej_p_sim'] = kwd_rej_p_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8aGSNKMghlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kwd_acc_f_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  kwd = set(', '.join(row.keywords).replace(',', '').split(' '))\n",
        "  accepted_f = set(row.accepted_function.replace(',', '').split(' '))\n",
        "  kwd_acc_f_sim.append(len(kwd.intersection(accepted_f)) / len(kwd.union(accepted_f)))\n",
        "\n",
        "train_df['kwd_acc_f_sim'] = kwd_acc_f_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvz91XPghjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kwd_rej_f_sim = []\n",
        "for row in train_df.itertuples():\n",
        "  kwd = set(', '.join(row.keywords).replace(',', '').split(' '))\n",
        "  rejected_f = set(row.rejected_function.replace(',', '').split(' '))\n",
        "  kwd_rej_f_sim.append(len(kwd.intersection(rejected_f)) / len(kwd.union(rejected_f)))\n",
        "\n",
        "train_df['kwd_rej_f_sim'] = kwd_rej_f_sim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3u7x0YyghgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['dif_kwd_acc_p_rej_p'] = train_df['kwd_acc_p_sim'] - train_df['kwd_rej_p_sim']\n",
        "train_df['dif_kwd_acc_j_rej_j'] = train_df['kwd_acc_f_sim'] - train_df['kwd_rej_f_sim']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdVVUP5scbF",
        "colab_type": "text"
      },
      "source": [
        "## All accepted and rejected fraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KmspEjjeaK2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_accepted_function = set()\n",
        "all_rejected_function = set()\n",
        "\n",
        "all_accepted_product = set()\n",
        "all_rejected_product = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lwt9o0tX3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row in train_df.itertuples():\n",
        "  all_accepted_function = all_accepted_function.union(set(row.accepted_function.split(', ')))\n",
        "  all_rejected_function = all_rejected_function.union(set(row.rejected_function.split(', ')))\n",
        "  all_accepted_product = all_accepted_product.union(set(row.accepted_product.split(', ')))\n",
        "  all_rejected_product = all_rejected_product.union(set(row.rejected_product.split(', ')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWAIH_LotX0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frc_acc_f = []\n",
        "frc_rej_f = []\n",
        "frc_acc_p = []\n",
        "frc_rej_p = []\n",
        "\n",
        "for row in train_df.itertuples():\n",
        "  frc_acc_f.append(len(set(row.accepted_function.split(', '))) / len(all_accepted_function))\n",
        "  frc_rej_f.append(len(set(row.rejected_function.split(', '))) / len(all_rejected_function))\n",
        "\n",
        "  frc_acc_p.append(len(set(row.accepted_product.split(', '))) / len(all_accepted_product))\n",
        "  frc_rej_p.append(len(set(row.rejected_product.split(', '))) / len(all_rejected_product))\n",
        "\n",
        "train_df['frc_acc_f'] = frc_acc_f\n",
        "train_df['frc_rej_f'] = frc_rej_f\n",
        "train_df['frc_acc_p'] = frc_acc_p\n",
        "train_df['frc_rej_p'] = frc_rej_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae6wxd50HX5d",
        "colab_type": "text"
      },
      "source": [
        "## Accepted and rejected fraction (target=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQQmO1dSLKEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['frc_acc_f_0'] = 0\n",
        "train_df['frc_rej_f_0'] = 0\n",
        "train_df['frc_acc_p_0'] = 0\n",
        "train_df['frc_rej_p_0'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN6ZbJkAIEUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_accepted_function_0 = set()\n",
        "all_rejected_function_0 = set()\n",
        "\n",
        "all_accepted_product_0 = set()\n",
        "all_rejected_product_0 = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkxGDAqNH3sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row in train_df.itertuples():\n",
        "  if row.target != 0:\n",
        "    continue\n",
        "  all_accepted_function_0 = all_accepted_function_0.union(set(row.accepted_function.split(', ')))\n",
        "  all_rejected_function_0 = all_rejected_function_0.union(set(row.rejected_function.split(', ')))\n",
        "  all_accepted_product_0 = all_accepted_product_0.union(set(row.accepted_product.split(', ')))\n",
        "  all_rejected_product_0 = all_rejected_product_0.union(set(row.rejected_product.split(', ')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QOY25d2yfNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in enumerate(train_df.itertuples()):\n",
        "  if row.target != 0:\n",
        "    continue\n",
        "  train_df.loc[idx, 'frc_acc_f_0'] = len(set(row.accepted_function.split(', '))) / len(all_accepted_function_0)\n",
        "  train_df.loc[idx, 'frc_rej_f_0'] = len(set(row.rejected_function.split(', '))) / len(all_rejected_function_0)\n",
        "\n",
        "  train_df.loc[idx, 'frc_acc_p_0'] = len(set(row.accepted_product.split(', '))) / len(all_accepted_product_0)\n",
        "  train_df.loc[idx, 'frc_rej_p_0'] = len(set(row.rejected_product.split(', '))) / len(all_rejected_product_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnttg2Y8KE7S",
        "colab_type": "text"
      },
      "source": [
        "## Accepted and rejected fraction (target=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeHVn5c8KHnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_accepted_function_1 = set()\n",
        "all_rejected_function_1 = set()\n",
        "\n",
        "all_accepted_product_1 = set()\n",
        "all_rejected_product_1 = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDy8CpKlKHkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row in train_df.itertuples():\n",
        "  if row.target != 1:\n",
        "    continue\n",
        "  all_accepted_function_1 = all_accepted_function_1.union(set(row.accepted_function.split(', ')))\n",
        "  all_rejected_function_1 = all_rejected_function_1.union(set(row.rejected_function.split(', ')))\n",
        "  all_accepted_product_1 = all_accepted_product_1.union(set(row.accepted_product.split(', ')))\n",
        "  all_rejected_product_1 = all_rejected_product_1.union(set(row.rejected_product.split(', ')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlBhNCnQKHiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in enumerate(train_df.itertuples()):\n",
        "  if row.target != 1:\n",
        "    continue\n",
        "  train_df.loc[idx, 'frc_acc_f_1'] = len(set(row.accepted_function.split(', '))) / len(all_accepted_function_1)\n",
        "  train_df.loc[idx, 'frc_rej_f_1'] = len(set(row.rejected_function.split(', '))) / len(all_rejected_function_1)\n",
        "\n",
        "  train_df.loc[idx, 'frc_acc_p_1'] = len(set(row.accepted_product.split(', '))) / len(all_accepted_product_1)\n",
        "  train_df.loc[idx, 'frc_rej_p_1'] = len(set(row.rejected_product.split(', '))) / len(all_rejected_product_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgMD0yg6KGD4",
        "colab_type": "text"
      },
      "source": [
        "## Accepted and rejected fraction (target=2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4iwl6HeKIK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_accepted_function_2 = set()\n",
        "all_rejected_function_2 = set()\n",
        "\n",
        "all_accepted_product_2 = set()\n",
        "all_rejected_product_2 = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1BVFqUlKIHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for row in train_df.itertuples():\n",
        "  if row.target != 2:\n",
        "    continue\n",
        "  all_accepted_function_2 = all_accepted_function_2.union(set(row.accepted_function.split(', ')))\n",
        "  all_rejected_function_2 = all_rejected_function_2.union(set(row.rejected_function.split(', ')))\n",
        "  all_accepted_product_2 = all_accepted_product_2.union(set(row.accepted_product.split(', ')))\n",
        "  all_rejected_product_2 = all_rejected_product_2.union(set(row.rejected_product.split(', ')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dszLgJdsKIEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx, row in enumerate(train_df.itertuples()):\n",
        "  if row.target != 2:\n",
        "    continue\n",
        "  train_df.loc[idx, 'frc_acc_f_2'] = len(set(row.accepted_function.split(', '))) / len(all_accepted_function_2)\n",
        "  train_df.loc[idx, 'frc_rej_f_2'] = len(set(row.rejected_function.split(', '))) / len(all_rejected_function_2)\n",
        "\n",
        "  train_df.loc[idx, 'frc_acc_p_2'] = len(set(row.accepted_product.split(', '))) / len(all_accepted_product_2)\n",
        "  train_df.loc[idx, 'frc_rej_p_2'] = len(set(row.rejected_product.split(', '))) / len(all_rejected_product_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbWQfASDNIrN",
        "colab_type": "text"
      },
      "source": [
        "## Dropping HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppoH5_PtKIBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df.drop(['html'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw4nuvh-NUq4",
        "colab_type": "text"
      },
      "source": [
        "## KNN features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrdibuESNTSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
        "    '''\n",
        "        This class should implement KNN features extraction \n",
        "    '''\n",
        "    def __init__(self, n_jobs, k_list, metric, n_classes=None, n_neighbors=None, eps=1e-6):\n",
        "        self.n_jobs = n_jobs\n",
        "        self.k_list = k_list\n",
        "        self.metric = metric\n",
        "        \n",
        "        if n_neighbors is None:\n",
        "            self.n_neighbors = max(k_list) \n",
        "        else:\n",
        "            self.n_neighbors = n_neighbors\n",
        "            \n",
        "        self.eps = eps        \n",
        "        self.n_classes_ = n_classes\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "            Set's up the train set and self.NN object\n",
        "        '''\n",
        "        # Create a NearestNeighbors (NN) object. We will use it in `predict` function \n",
        "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list), \n",
        "                                      metric=self.metric, \n",
        "                                      n_jobs=1, \n",
        "                                      algorithm='brute' if self.metric=='cosine' else 'auto')\n",
        "        self.NN.fit(X)\n",
        "        \n",
        "        # Store labels \n",
        "        self.y_train = y\n",
        "        \n",
        "        # Save how many classes we have\n",
        "        self.n_classes = np.unique(y).shape[0] if self.n_classes_ is None else self.n_classes_\n",
        "        \n",
        "        \n",
        "    def predict(self, X):       \n",
        "        '''\n",
        "            Produces KNN features for every object of a dataset X\n",
        "        '''\n",
        "        if self.n_jobs == 1:\n",
        "            test_feats = []\n",
        "            for i in range(X.shape[0]):\n",
        "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
        "        else:\n",
        "            '''\n",
        "                 *Make it parallel*\n",
        "                     Number of threads should be controlled by `self.n_jobs`  \n",
        "                     \n",
        "                     \n",
        "                     You can use whatever you want to do it\n",
        "                     For Python 3 the simplest option would be to use \n",
        "                     `multiprocessing.Pool` (but don't use `multiprocessing.dummy.Pool` here)\n",
        "                     You may try use `joblib` but you will most likely encounter an error, \n",
        "                     that you will need to google up (and eventually it will work slowly)\n",
        "                     \n",
        "                     For Python 2 I also suggest using `multiprocessing.Pool` \n",
        "                     You will need to use a hint from this blog \n",
        "                     http://qingkaikong.blogspot.ru/2016/12/python-parallel-method-in-class.html\n",
        "                     I could not get `joblib` working at all for this code \n",
        "                     (but in general `joblib` is very convenient)\n",
        "                     \n",
        "            '''\n",
        "            test_feats =[]\n",
        "            \n",
        "            pool = Pool(processes=self.n_jobs) \n",
        "            for i in range(X.shape[0]):\n",
        "                test_feats.append(self.get_features_for_one(X[i:i+1]))\n",
        "                #test_feats.append(pool.apply_async(self.get_features_for_one, (X[i:i+1],)))\n",
        "          \n",
        "            test_feats = [res.get() for res in test_feats]\n",
        "        return np.vstack(test_feats)\n",
        "        \n",
        "        \n",
        "    def get_features_for_one(self, x):\n",
        "        '''\n",
        "            Computes KNN features for a single object `x`\n",
        "        '''\n",
        "\n",
        "        NN_output = self.NN.kneighbors(x)\n",
        "        \n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores indices of the neighbors\n",
        "        neighs = NN_output[1][0]\n",
        "        \n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores distances to corresponding neighbors\n",
        "        neighs_dist = NN_output[0][0] \n",
        "\n",
        "        # Vector of size `n_neighbors`\n",
        "        # Stores labels of corresponding neighbors\n",
        "        neighs_y = self.y_train[neighs] \n",
        "        \n",
        "        ## ========================================== ##\n",
        "        ##              YOUR CODE BELOW\n",
        "        ## ========================================== ##\n",
        "        \n",
        "        # We will accumulate the computed features here\n",
        "        # Eventually it will be a list of lists or np.arrays\n",
        "        # and we will use np.hstack to concatenate those\n",
        "        return_list = [] \n",
        "        \n",
        "        \n",
        "        ''' \n",
        "            1. Fraction of objects of every class.\n",
        "               It is basically a KNNСlassifiers predictions.\n",
        "\n",
        "               Take a look at `np.bincount` function, it can be very helpful\n",
        "               Note that the values should sum up to one\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            feats = np.bincount(neighs_y[:k],minlength=self.n_classes)\n",
        "            feats  = feats / feats.sum()\n",
        "            \n",
        "            assert len(feats) == self.n_classes\n",
        "            return_list += [feats]\n",
        "        \n",
        "        \n",
        "        '''\n",
        "            2. Same label streak: the largest number N, \n",
        "               such that N nearest neighbors have the same label.\n",
        "               \n",
        "               What can help you: `np.where`\n",
        "        '''\n",
        "        \n",
        "        if (neighs_y != neighs_y[0]).astype(int).sum() > 0:\n",
        "            feats = np.where(np.cumsum((neighs_y != neighs_y[0]).astype(int)) == 1)[0][0]\n",
        "        else:\n",
        "            feats = len(neighs_y)\n",
        "            \n",
        "        feats = [feats]\n",
        "        \n",
        "        assert len(feats) == 1\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            3. Minimum distance to objects of each class\n",
        "               Find the first instance of a class and take its distance as features.\n",
        "               \n",
        "               If there are no neighboring objects of some classes, \n",
        "               Then set distance to that class to be 999.\n",
        "\n",
        "               `np.where` might be helpful\n",
        "        '''\n",
        "        feats = []\n",
        "        for c in range(self.n_classes):\n",
        "            feat = neighs_dist[neighs_y == c][0] if (neighs_y == c).sum() > 0 else 999\n",
        "            feats.append(feat)\n",
        "        \n",
        "        assert len(feats) == self.n_classes\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            4. Minimum *normalized* distance to objects of each class\n",
        "               As 3. but we normalize (divide) the distances\n",
        "               by the distance to the closest neighbor.\n",
        "               \n",
        "               If there are no neighboring objects of some classes, \n",
        "               Then set distance to that class to be 999.\n",
        "               \n",
        "               Do not forget to add self.eps to denominator.\n",
        "        '''\n",
        "        feats = []\n",
        "        for c in range(self.n_classes):\n",
        "            feat = neighs_dist[neighs_y == c][0] if (neighs_y == c).sum() > 0 else 999\n",
        "            if feat!= 999:\n",
        "                feat = feat / (self.eps + neighs_dist[0])\n",
        "            feats.append(feat)\n",
        "        \n",
        "        assert len(feats) == self.n_classes\n",
        "        return_list += [feats]\n",
        "        \n",
        "        '''\n",
        "            5. \n",
        "               5.1 Distance to Kth neighbor\n",
        "                   Think of this as of quantiles of a distribution\n",
        "               5.2 Distance to Kth neighbor normalized by \n",
        "                   distance to the first neighbor\n",
        "               \n",
        "               feat_51, feat_52 are answers to 5.1. and 5.2.\n",
        "               should be scalars\n",
        "               \n",
        "               Do not forget to add self.eps to denominator.\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            \n",
        "            feat_51 = neighs_dist[k-1]\n",
        "            feat_52 = neighs_dist[k-1] / (neighs_dist[0] + self.eps)\n",
        "            \n",
        "            return_list += [[feat_51, feat_52]]\n",
        "        \n",
        "        '''\n",
        "            6. Mean distance to neighbors of each class for each K from `k_list` \n",
        "                   For each class select the neighbors of that class among K nearest neighbors \n",
        "                   and compute the average distance to those objects\n",
        "                   \n",
        "                   If there are no objects of a certain class among K neighbors, set mean distance to 999\n",
        "                   \n",
        "               You can use `np.bincount` with appropriate weights\n",
        "               Don't forget, that if you divide by something, \n",
        "               You need to add `self.eps` to denominator.\n",
        "        '''\n",
        "        for k in self.k_list:\n",
        "            numerator = np.zeros(self.n_classes)\n",
        "            denominator = np.full(self.n_classes, self.eps)\n",
        "            t = neighs_y[:k].max() + 1\n",
        "            numerator[:t] = np.bincount(neighs_y[:k], weights=neighs_dist[:k])\n",
        "            denominator[:t] = self.eps + np.bincount(neighs_y[:k])\n",
        "            feats = np.where(numerator>0, numerator/denominator, 999)\n",
        "            \n",
        "            assert len(feats) == self.n_classes\n",
        "            return_list += [feats]\n",
        "        \n",
        "        \n",
        "        # merge\n",
        "        knn_feats = np.hstack(return_list)\n",
        "        \n",
        "        return knn_feats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuHJNuqP3Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_df = train_df.select_dtypes(exclude=['object'])\n",
        "y_train = numeric_df.target\n",
        "numeric_df = scale(numeric_df.drop('target', axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o43zVj7nTgvW",
        "colab_type": "text"
      },
      "source": [
        "### Get feature for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kli657lTjwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "a404d28e-45b0-4640-b803-ad2f544c3f58"
      },
      "source": [
        "# We will use two metrics for KNN\n",
        "for metric in ['minkowski', 'cosine']:\n",
        "    print (metric)\n",
        "    \n",
        "    # Set up splitting scheme, use StratifiedKFold\n",
        "    # use skf_seed and n_splits defined above with shuffle=True\n",
        "    skf = StratifiedKFold(n_splits=n_splits, random_state=skf_seed, shuffle=True)\n",
        "    \n",
        "    # Create instance of our KNN feature extractor\n",
        "    # n_jobs can be larger than the number of cores\n",
        "    NNF = NearestNeighborsFeats(n_jobs=4, k_list=k_list, metric=metric)\n",
        "    \n",
        "    # Get KNN features using OOF use cross_val_predict with right parameters\n",
        "    preds = cross_val_predict(NNF, numeric_df, y_train, cv=skf)\n",
        "    \n",
        "    # Save the features\n",
        "    np.save('knn_feats_%s_train.npy' % metric, preds)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minkowski\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-600a31bb669a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get KNN features using OOF use cross_val_predict with right parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNNF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Save the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    753\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    754\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 755\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_predict\u001b[0;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'decision_function'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_log_proba'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-3957dd1894c8>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mtest_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_features_for_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 \u001b[0;31m#test_feats.append(pool.apply_async(self.get_features_for_one, (X[i:i+1],)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-3957dd1894c8>\u001b[0m in \u001b[0;36mget_features_for_one\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Vector of size `n_neighbors`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Stores labels of corresponding neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mneighs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m## ========================================== ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"integer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1952\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             return self.obj._reindex_with_indexers(\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m         )\n\u001b[1;32m   1555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 1655\u001b[0;31m                     \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m                     \u001b[0;34m\"is no longer supported, see \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                     \u001b[0;34m\"https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\"\u001b[0m  \u001b[0;31m# noqa:E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Passing list-likes to .loc or [] with any missing labels is no longer supported, see https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adAUWVLmTjtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxhgB7DBQ7Tb",
        "colab_type": "text"
      },
      "source": [
        "### Get feature for test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz9Bhny8yfLx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f375af8c-d599-47c3-9cc1-19486a110f33"
      },
      "source": [
        "for metric in ['minkowski', 'cosine']:\n",
        "  print (metric)\n",
        "\n",
        "  # Create instance of our KNN feature extractor\n",
        "  NNF = NearestNeighborsFeats(n_jobs=1, k_list=k_list, metric='minkowski')\n",
        "\n",
        "  # Fit on train set\n",
        "  NNF.fit(numeric_df, y_train)\n",
        "\n",
        "  # Get features for test\n",
        "  test_knn_feats = NNF.predict(X_test)\n",
        "  \n",
        "  # Dump the features to disk\n",
        "  np.save('knn_feats_%s_test.npy' % metric , test_knn_feats)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "minkowski\n",
            "cosine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BfqN5oiyfEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "36c22594-339d-4cfe-f885-a34640aa7aef"
      },
      "source": [
        "numeric_df"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.38612048, -0.10467775, -0.09576705, ...,  0.59945067,\n",
              "         0.11041439,  0.19980637],\n",
              "       [-2.58986523, -0.340922  , -0.09576705, ...,  1.61232234,\n",
              "         0.11041439,  0.19980637],\n",
              "       [ 0.38612048, -0.11412752, -0.09576705, ..., -0.41342101,\n",
              "        -0.24610575, -0.25547279],\n",
              "       ...,\n",
              "       [ 0.38612048,  0.44340891, -0.09576705, ..., -0.41342101,\n",
              "        -0.24610575, -0.25547279],\n",
              "       [ 0.38612048, -0.55826671, -0.09576705, ..., -0.41342101,\n",
              "        -0.24610575, -0.25547279],\n",
              "       [ 0.38612048,  2.56015738, -0.09576705, ..., -0.41342101,\n",
              "        -0.24610575, -0.25547279]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWS44M2ye-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d473c86f-fc38-4db5-fc2d-495b2fb1662a"
      },
      "source": [
        "numeric_df.head()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>html_page_cnt</th>\n",
              "      <th>text_rows_mean</th>\n",
              "      <th>is_mis_accepted_function</th>\n",
              "      <th>is_mis_rejected_function</th>\n",
              "      <th>is_mis_accepted_product</th>\n",
              "      <th>is_mis_rejected_product</th>\n",
              "      <th>is_mis_keyword</th>\n",
              "      <th>have_error</th>\n",
              "      <th>acc_f_rej_f_sim</th>\n",
              "      <th>acc_p_rej_p_sim</th>\n",
              "      <th>kwd_acc_p_sim</th>\n",
              "      <th>kwd_rej_p_sim</th>\n",
              "      <th>kwd_acc_f_sim</th>\n",
              "      <th>kwd_rej_f_sim</th>\n",
              "      <th>dif_kwd_acc_p_rej_p</th>\n",
              "      <th>dif_kwd_acc_j_rej_j</th>\n",
              "      <th>frc_acc_f</th>\n",
              "      <th>frc_rej_f</th>\n",
              "      <th>frc_acc_p</th>\n",
              "      <th>frc_rej_p</th>\n",
              "      <th>frc_acc_f_0</th>\n",
              "      <th>frc_rej_f_0</th>\n",
              "      <th>frc_acc_p_0</th>\n",
              "      <th>frc_rej_p_0</th>\n",
              "      <th>frc_acc_f_1</th>\n",
              "      <th>frc_rej_f_1</th>\n",
              "      <th>frc_acc_p_1</th>\n",
              "      <th>frc_rej_p_1</th>\n",
              "      <th>frc_acc_f_2</th>\n",
              "      <th>frc_rej_f_2</th>\n",
              "      <th>frc_acc_p_2</th>\n",
              "      <th>frc_rej_p_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.047619</td>\n",
              "      <td>0.044776</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002843</td>\n",
              "      <td>0.018265</td>\n",
              "      <td>0.011785</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018349</td>\n",
              "      <td>0.011885</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019787</td>\n",
              "      <td>0.023569</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019878</td>\n",
              "      <td>0.023769</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031963</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032061</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>0.004255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.015221</td>\n",
              "      <td>0.023569</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015291</td>\n",
              "      <td>0.023769</td>\n",
              "      <td>0.002597</td>\n",
              "      <td>0.004149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>0.018868</td>\n",
              "      <td>0.064516</td>\n",
              "      <td>-0.000349</td>\n",
              "      <td>0.010654</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.036364</td>\n",
              "      <td>0.004149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010687</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.004255</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  html_page_cnt  text_rows_mean  ...  frc_rej_f_2  frc_acc_p_2  frc_rej_p_2\n",
              "0       2              2              73  ...     0.011885     0.002597     0.004149\n",
              "1       2              1              48  ...     0.023769     0.002597     0.004149\n",
              "2       1              2              72  ...     0.000000     0.000000     0.000000\n",
              "3       2              2              11  ...     0.023769     0.002597     0.004149\n",
              "4       1              2              40  ...     0.000000     0.000000     0.000000\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTzcFOEqye8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCeOcn21tXw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuOliNN0okSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKPQnmPokPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}