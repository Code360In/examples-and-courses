{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a little hack to change font size for Markdown cells\n",
    "from IPython.core.display import Javascript, display\n",
    "\n",
    "def set_markdown_font():\n",
    "    javascript = \"\"\"\n",
    "    var _render = IPython.MarkdownCell.prototype.render;\n",
    "\n",
    "    if (_render.decorator === undefined) {\n",
    "      IPython.MarkdownCell.prototype.render = function () {\n",
    "        this.element.find('.rendered_html p').css('font-size', '20px');\n",
    "        return _render.apply(this, arguments);\n",
    "      }\n",
    "      IPython.MarkdownCell.prototype.render.decorator = true;\n",
    "    }\n",
    "    \"\"\"\n",
    "    display(Javascript(data=javascript))\n",
    "\n",
    "set_markdown_font()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Networks are highly expressive machine learning networks that have been around for many decades.\n",
    "The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutional Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodfellow (do you know who is this guy?) et al. published a paper [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572) in 2014 showing that adding imperceptible perturbations to an image can cause drastically different model performance.\n",
    "\n",
    "Given this tutorial, we will explore the topic via example on an image classifier. Specifically we will use one of the first and most popular attack methods, the Fast Gradient Sign Attack (FGSM), to fool an MNIST classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general the overall goal of an attacker is to add the least amount of perturbation to the input data to cause the desired misclassification.\n",
    "\n",
    "There are several kinds of assumptions of the attacker’s knowledge, two of which are:\n",
    "- **white-box**\n",
    "- **black-box**.\n",
    "\n",
    "A *white-box* attack assumes the attacker has full knowledge and access to the model, including architecture, inputs, outputs, and weights.\n",
    "\n",
    "A *black-box* attack assumes the attacker only has access to the inputs and outputs of the model, and knows nothing about the underlying architecture or weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also several types of goals and one of the most popular is **misclassification**. It can be targeted or untargeted.\n",
    "\n",
    "An  *untargeted misclassification* means the adversary only wants the output classification to be wrong but does not care what the new classification is.\n",
    "\n",
    "A *targeted misclassification* means the adversary wants to alter an image that is originally of a specific source class so that it is classified as a specific target class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first and most popular adversarial attacks to date is referred to as the **Fast Gradient Sign Attack** (FGSM) and is described in the beforementioned paper.\n",
    "\n",
    "The attack is remarkably powerful, and yet intuitive. It is designed to attack neural networks by leveraging the way they learn, *gradients*.\n",
    "\n",
    "The idea is simple, rather than working to minimize the loss by adjusting the weights based on the backpropagated gradients, the attack *adjusts the input data to maximize the loss* based on the same backpropagated gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at the famous FGSM panda example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![This is not a panda](fgsm_panda_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attack backpropagates the gradient back to the input data to calculate gradient of _y_ with respect to *x*.\n",
    "\n",
    "Then, it adjusts the input data by a small step (ϵ or 0.007 in the picture) in the direction of gradient\n",
    "(notice that we take only **sign**, not gradient values) that will maximize the loss.\n",
    "\n",
    "The resulting perturbed image, *x*, is then misclassified by the target network as a “gibbon” when it is still clearly a “panda”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an implementation of the [LeNet](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html) architecture for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what device we are using\n",
    "print(\"CUDA Available: \",torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of note: This notebook uses only a single GPU.\n",
    "PyTorch can run models on several GPU, try to search how to specify several GPUs and create several devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download weights of already pretrained model or train a network from scratch to see how long does it take\n",
    "and how accuracy of the model changes during the training.\n",
    "\n",
    "Notice that a model will work in *evulation mode*, i.e. weigths are not trainable and dropout is not applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "pretrained_model = 'lenet/mnist-model.pth'\n",
    "\n",
    "import os\n",
    "os.makedirs('lenet', exist_ok=True)\n",
    "\n",
    "import requests\n",
    "url = 'https://drive.google.com/drive/folders/1fn83DF14tWmit0RTKWRhPq5uVXt73e0h?usp=sharing'\n",
    "\n",
    "r = requests.get(url)\n",
    "with open(pretrained_model, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or inspect code for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist', \n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 20\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Remember a line with model.to(device)?\n",
    "        # It moves a model to a GPU and PyTorch expects that\n",
    "        # input data also will be on the GPU where the model resides\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Calculate the error between model predictins and actual labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Initiate backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print(f'[Epoch {epoch + 1}: batch {i + 1}] loss: {running_loss / 200}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how accurate is our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = datasets.MNIST('./mnist',\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                           ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent training\n",
    "model.eval()\n",
    "\n",
    "total_correct = 0\n",
    "avg_loss = 0.0\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "   \n",
    "    output = model(inputs)\n",
    "    avg_loss += criterion(output, labels).sum()\n",
    "    \n",
    "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad.\n",
    "    # It detaches the output from the computational graph.\n",
    "    # So no gradient will be backpropagated along this variable.\n",
    "    pred = output.detach().max(1)[1]\n",
    "    total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "avg_loss /= len(data_test)\n",
    "avg_loss = avg_loss.detach().cpu().item()\n",
    "accuracy = float(total_correct) / len(data_test)\n",
    "print(f'Test Avg. Loss: {avg_loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model state for re-use\n",
    "my_awesome_model = 'my-lenet.pth'\n",
    "torch.save(model.state_dict(), my_awesome_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of training code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FGSM Attack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fgsm_attack function takes three inputs: image is the original clean image (x), epsilon is the pixel-wise perturbation amount (ϵ), and data_grad is gradient of the loss w.r.t the input image.\n",
    "\n",
    "The function then creates perturbed image as\n",
    "\n",
    "$$\\text{perturbed image} = image + epsilon * sign(gradient) = x + ϵ ∗ sign(∇xJ(θ,x,y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon * sign_data_grad\n",
    "    \n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # MNIST Test dataset and dataloader declaration\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./mnist',\n",
    "                   train=False,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                   ])),\n",
    "    batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test function performs a full test step on the MNIST test set and reports a final accuracy.\n",
    "\n",
    "For each sample in the test set, the function computes the gradient of the loss w.r.t the input data (data_grad),  creates a perturbed image with fgsm_attack (perturbed_data), then checks to see if the perturbed example is adversarial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, device, test_loader, epsilon ):\n",
    "\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss - Negative Log Likehood\n",
    "        # Loosely explained at https://medium.com/deeplearningmadeeasy/negative-log-likelihood-6bd79b55d8b6\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "# Epsilon 0 means no attack at all\n",
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "# Run test for each epsilon\n",
    "for eps in epsilons:\n",
    "    acc, ex = test(model, device, test_loader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first result is the accuracy versus epsilon plot.\n",
    "\n",
    "As epsilon increases we expect the test accuracy to decrease and it actually does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, epsilons[-1] + 0.05, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a tradeoff between accuracy degredation and perceptibility that an attacker must consider.  \n",
    "\n",
    "Below are some examples of successful adversarial examples at each epsilon value.  \n",
    "Each row of the plot shows a different epsilon value. The first row is the ϵ=0 examples which represent the original “clean” images with no perturbation. The title of each image shows the “original classification -> adversarial classification.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "   # Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "        orig, adv, ex = examples[i][j]\n",
    "        plt.title(\"True {} -> Adv {}\".format(orig, adv))\n",
    "        plt.imshow(ex, cmap=\"gray\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a closer look at how we calculated gradient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, target in test_loader:  \n",
    "    data, target = data.to(device), target.to(device)\n",
    "    data.requires_grad = True\n",
    "    \n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "   \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    data_grad = data.grad.data\n",
    "    perturbed_data = fgsm_attack(data, epsilon, data_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second parameter to the loss function is a true label of the current image. After that gradient is used for perturbation generation.\n",
    "<br>\n",
    "<br>\n",
    "Remember that gradient is obtained for the whole image\n",
    "pixels, namely gradient shape is equal to the image shape.  \n",
    "In our case it's (28, 28, 1). So **each pixel gets own perturbation**.\n",
    "\n",
    "Now recall how we apply gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_data_grad = data_grad.sign()\n",
    "perturbed_image = image + epsilon * sign_data_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the scaled gradient to the original image. The result of this action is misclassification, but we don't know what label gain higher confidence. This is a case of *untargeted misclassification*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Targeted misclassification* implies that you add perturbation and model predicts one of the possible labels but not the correct one. For achieving this you should take gradient with respect to you selected label.\n",
    "\n",
    "But it's not enough. Also, you should subtract scaled gradient instead of adding. Doing this we actually perform gradient descent on the loss function surface in direction to the target class. Remember that we want **to minimize** loss function with respect to **selected class**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICUM TASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - For each class select 10 images not from this class. Perform attack to move selected images to this class. for each class select image with highest confidence.\n",
    "    \n",
    "Best sample is the one with higher confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Try different epsilons for one selected class and collect the number of iterations required to achieve success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3* OPTIONAL - make attacks using a model trained on Cifar10 obtained from the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
