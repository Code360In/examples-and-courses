{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[homework]yolov3_detection.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jw62Tvj4hYAX","colab_type":"text"},"source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"CFP-hx2hhYAZ","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"rG3hsoqchYAb","colab_type":"text"},"source":["<h2 style=\"text-align: center;\"><b>Детектирование объектов с помощью YOLOv3</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"hhg_6vXJhYAd","colab_type":"text"},"source":["<img src=\"https://i.ytimg.com/vi/s8Ui_kV9dhw/maxresdefault.jpg\" width=600 height=450>"]},{"cell_type":"markdown","metadata":{"id":"1imW2qaNhYAe","colab_type":"text"},"source":["<h4 style=\"text-align: center;\"><b>Составитель: Илья Захаркин (ФИВТ МФТИ, NeurusLab). По всем вопросам в Telegram: <a>@ilyazakharkin</a></b></h4>"]},{"cell_type":"markdown","metadata":{"id":"AwWEc5mvhYAf","colab_type":"text"},"source":["На семинаре мы запускали SSD и Mask-RCNN из Tensorflow Object Detection API. На лекции же подробно разбирался алгоритм YOLOv3, давайте же теперь этот самый детектор и попробуем применить на практике."]},{"cell_type":"markdown","metadata":{"id":"kgbwDaZVhYAg","colab_type":"text"},"source":["<h2 style=\"text-align: center;\"><b>YOLOv3</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"hOoIlGE7hYAi","colab_type":"text"},"source":["**Идея детекторов:** использовать сильную свёрточную нейросеть, натренированную на классификации, чтобы извлечь признаки из изображения, потом использовать свёрточные слои для регрессии точек боксов и классификации объектов внутри них."]},{"cell_type":"markdown","metadata":{"id":"hZ--6lpXhYAi","colab_type":"text"},"source":["Напомним, что архитектура у YOLOv3 следующая:"]},{"cell_type":"markdown","metadata":{"id":"NTVj9YqzhYAk","colab_type":"text"},"source":["<img src=\"https://camo.githubusercontent.com/5c561504c1b01ee565764785efe5572156d4cd61/68747470733a2f2f692e696d6775722e636f6d2f546f45626c6a5a2e706e67\">"]},{"cell_type":"markdown","metadata":{"id":"elGJ-XsKhYAm","colab_type":"text"},"source":["Словами:\n","\n","1. Картинка подаётся на вход\n","2. Она сжимается до размера 300х300х3\n","3. Пропускается через backbone-нейросеть, которая извлекает признаки -- *Darknet53*\n","4. Идут несколько свёрточных слоёв со свёртками 1х1 и 3х3\n","5. После них идёт yolo-слой: свёртка 1х1х(1 + 4 + NUM_CLASSES)\n","6. Далее происходит upsampling (увеличение по ширине и высоте) в 2 раза и конкатенация с feature map'ами, которые были до upsampling'а (чтобы улучшить качество)\n","7. Шаги 4-6 повторяются ещё 2 раза, чтобы улучшить качество детектирования мелких объектов\n","\n","При обучении также: \n","8. Финальный feature map специальным образом подаётся в Loss для подсчёта ошибки\n","9. Распространятся градиенты, как в обычном backpropagation, обновляются веса сети\n","\n","В слоях используются LeakyReLU активации. Перед YOLO-слоями используются линейные активации (то есть нет нелинейности)."]},{"cell_type":"markdown","metadata":{"id":"5uVEL-AShYAx","colab_type":"text"},"source":["Как вся архитектура выглядит в коде вы можете посмотреть в этом файле: https://github.com/akozd/tensorflow_yolo_v3/blob/master/models/yolo_v3.py"]},{"cell_type":"markdown","metadata":{"id":"mCtcPtCdhYA0","colab_type":"text"},"source":["Оригинальная статья с arxiv.org: https://arxiv.org/abs/1804.02767"]},{"cell_type":"markdown","metadata":{"id":"As2Wu5HphYA2","colab_type":"text"},"source":["***Примечание:*** Вы можете спросить: \"Почему именно YOLOv3, ведь много других хороших детекторов?\". Да, но на данный момент у YOLOv3 лучшее соотношение скорость/качество из широко применяемых нейросетевых детекторов. В этом плане он State-of-the-Art."]},{"cell_type":"markdown","metadata":{"id":"1zJ-BTnFhYA5","colab_type":"text"},"source":["<h2 style=\"text-align: center;\"><b>Задание (10 баллов)</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"NEQt1fWzhYA6","colab_type":"text"},"source":["***Предполагается, что Вы знакомы с TensorFlow и  свёрточными нейросетями***"]},{"cell_type":"markdown","metadata":{"id":"agYWNq_AhYA7","colab_type":"text"},"source":["Лучше выполнять этот ноутбук локально, поставив TensorFlow: `pip install tensorflow` (CPU-версия, но слишком долго работать не будет, так как обучения в задании нет, только предсказание).\n","\n","Если Вы выполняете на Google Colab, то будьте готовы активно использовать переходы в подпапки (`os.chdir(*path*)`), как было на семинаре."]},{"cell_type":"markdown","metadata":{"id":"g-XgDUnKhYA-","colab_type":"text"},"source":["<img src=\"http://blog.yavuzz.com/image.axd?picture=/resimler/sayit.jpg\">"]},{"cell_type":"markdown","metadata":{"id":"Kt5LPwClhYA_","colab_type":"text"},"source":["Писать свой нейросетевой детектор с нуля -- весьма непростая задача, поэтому сейчас просто используем код человека, который смог: https://github.com/akozd/tensorflow_yolo_v3"]},{"cell_type":"markdown","metadata":{"id":"vEvq4V9ZhYBA","colab_type":"text"},"source":["Напомню, что скачать с Github весь репозиторий можно командой: `git clone *адрес репозитория*`. Например, репозиторий, который нужен в этом задании, скачивается так: `git clone https://github.com/akozd/tensorflow_yolo_v3`"]},{"cell_type":"markdown","metadata":{"id":"fFQRhOO-hYBC","colab_type":"text"},"source":["### Этап 1 (2 балла): первичное ознакомлене с репозиторием"]},{"cell_type":"markdown","metadata":{"id":"L24sYtwphYBD","colab_type":"text"},"source":["Прочитать README этого репозитория: https://github.com/akozd/tensorflow_yolo_v3"]},{"cell_type":"markdown","metadata":{"id":"48R4VC6mhYBG","colab_type":"text"},"source":["***Вопрос по `README.md` (1 балл)***: что автор репозитория предлагает для того, чтобы улучшить качество предсказания боксов пр обучении на собственных данных?"]},{"cell_type":"code","metadata":{"id":"fqS_pEk0hYBH","colab_type":"code","colab":{}},"source":["<Ответ>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1zpCKuIhYBL","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EThyEadAhYBN","colab_type":"text"},"source":["Прочитайте файл `train.py`"]},{"cell_type":"markdown","metadata":{"id":"XBnL-rXZhYBO","colab_type":"text"},"source":["***Вопрос по `train.py` (1 балл)***: за что отвечает аргумент скрипта `train.py` под названием `--test_model_overfit`?"]},{"cell_type":"code","metadata":{"id":"pYih2WavhYBQ","colab_type":"code","colab":{}},"source":["<Развёрнутый ответ>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOQOS5ZIhYBW","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7VosIiRhYBZ","colab_type":"text"},"source":["### Этап 2 (3 балла): чтение кода репозитория"]},{"cell_type":"markdown","metadata":{"id":"tzvabtGshYBc","colab_type":"text"},"source":["Теперь нужно прочитать код автора и понять, что в нём происходит. Этот репозиторий был выбран не спроста -- весь код хорошо документирован и исправно работает.  \n","\n","Ваша задача состоит в том, чтобы понять, как связаны файлы друг с другом, какие файлы используются для обучения, какие для предсказания, какие вовсе не используются. Хорошая стратегия: основываясь на README.md начать разбираться с тем, как работает `detect.py`, то есть что принимает на вход и что на выход, какие сторонние файлы использует."]},{"cell_type":"markdown","metadata":{"id":"zflhUP11hYBd","colab_type":"text"},"source":["<img src=\"https://thefreshtoast.com/wp-content/uploads/2017/02/bbc-new-meme-hood-documentary.jpg\" width=500 height=300>"]},{"cell_type":"markdown","metadata":{"id":"-9em8NGdhYBf","colab_type":"text"},"source":["***Задача (3 балла)***: подробно опишите структуру репозитория, пояснив, для чего нужен каждый файл. Чем более подробно вы опишите, что происходит внутри файла (можно прямо в виде \"..в строчках 15-20 производится предсказание боксов по изображению..\"), тем больше баллов получите."]},{"cell_type":"code","metadata":{"id":"3Z5W_Sy5hYBf","colab_type":"code","colab":{}},"source":["<Подробное описание структуры репозитория>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c2gA44FhYBi","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVNrpN3PhYBq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nla1NXMVhYBt","colab_type":"text"},"source":["### Этап 3 (5 баллов): установка нужных зависимостей, скачивание весов (`.ckpt`) и запуск `detect.py` на ваших изображениях"]},{"cell_type":"markdown","metadata":{"id":"LkOk9H39hYBu","colab_type":"text"},"source":["Разомнём пальцы и позапускаем код из репозитория на ваших изображениях (любых, однако желательно, чтобы на них были объекты из [этого списка](https://github.com/nightrome/cocostuff/blob/master/labels.md), так как изначально детектор обучен на COCO датсете)."]},{"cell_type":"markdown","metadata":{"id":"ej5L4SbRhYBv","colab_type":"text"},"source":["<img src=\"http://static.hdw.eweb4.com/media/wallpapers_dl/1/89/882736-adventure-time-with-finn-and-jake.jpg\" width=400 height=300>"]},{"cell_type":"markdown","metadata":{"id":"MIYrlDh7hYBx","colab_type":"text"},"source":["Сначала убедитесь, что у вас (или на Colab) стоят все нужные зависимости (5 ссылок в разделе Dependencdies в README.md).  \n","Потом либо скриптом `.sh`, либо по ссылке, данной в ридми, скачайте в папку `model_weights` веса обученной на датасете COCO YOLOv3-модели."]},{"cell_type":"markdown","metadata":{"id":"xLSx7-vLhYBx","colab_type":"text"},"source":["Баллы в этом задании ставятся следующим образом:"]},{"cell_type":"markdown","metadata":{"id":"XEhJ8CpdhYB0","colab_type":"text"},"source":["* (1 балл) получены предсказания на любом вашем изображении (этот пункт служит подтверждением того, что у вас всё запустилось и вы смогли скачать и настроить репозиторий у себя/в колабе)  \n","* (1 балл) найдена кратинка, где у нейросети есть ложные срабатывания (false positives)  \n","* (1 балл) найдена картинка, где у нейросети есть пропуски в детекции (false negatives)  \n","* (1 балл) найдена картинка, где сеть детектировала успешно все объекты, хотя они сильно перекрыватся\n","* (1 балл) предыдущий пункт, но наоброт -- нейросеть справляется плохо"]},{"cell_type":"code","metadata":{"id":"S0pLrYsohYB0","colab_type":"code","colab":{}},"source":["<Вашы попытки здесь>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTJCqy1XhYB6","colab_type":"code","colab":{}},"source":["<и здесь>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jT16UTTRhYB9","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0i9fZpMAhYCA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kus1sndThYCD","colab_type":"text"},"source":["### * Дополнительный этап 4 (10 баллов): обучение детектора на собственной выборке"]},{"cell_type":"markdown","metadata":{"id":"b-5tGWJuhYCE","colab_type":"text"},"source":["<img src=\"https://i.ytimg.com/vi/Zdf7Afgfq8Q/maxresdefault.jpg\" width=500 height=300>"]},{"cell_type":"markdown","metadata":{"id":"K2eSSl49hYCE","colab_type":"text"},"source":["В этом задании Вы по-желанию можете обучить свой детектор. Чтобы упростить задачу, вот примеры небольших датасетов, на которых можно обучить и протестировать (**10 баллов ставится за один из двух вариантов, за оба варианта двойной балл ставиться не будет**):"]},{"cell_type":"markdown","metadata":{"id":"8ayuId_lhYCF","colab_type":"text"},"source":["***1). Датасет игровых карт: https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10***  \n","\n","Репозиторий состоит из туториала по обучению детектора с помощью TF Object Detection API. Вы можете либо взять датасет из папки `/images` этого репозитория и обучить текущий YOLOv3 с помощью `train.py` (готовьтесь, предстоит повозиться с переводом разметки данных в нужный формат), либо же пройти тот туториал и обучить любую модель из TF Object Detection API на этом датасете.  \n","\n","Главное: продемонстрировать работу вашего детектора не тестовых примерах с картами."]},{"cell_type":"code","metadata":{"id":"y3bc-OYahYCG","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp0haup-hYCI","colab_type":"code","colab":{}},"source":["<Ты сможешь!>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"97SwkwqYhYCK","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kWCLz1ybhYCN","colab_type":"text"},"source":["**2). Датасет из картинок со снитчем из Гарри Поттера, ссылка на статью с подробным описанием задачи: https://apptractor.ru/develop/syigraem-v-kviddich-s-tensorflow-object-detection-api.html**\n","\n","В качестве результата нужно показать тестовые изображения, на которых верно детектирован снитч."]},{"cell_type":"code","metadata":{"id":"zB5SqC6jhYCO","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ax0Pk-WohYCS","colab_type":"code","colab":{}},"source":["<Торжественно клянусь, что совершаю только шалость>"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjY1RZQVhYCV","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"InhMrYW1NSzR","colab_type":"text"},"source":["Также есть **ещё два пути, которые должны сработать**, если не работает то, что описано в домашнем ноутбуке:  \n","а). **Darkflow** -- репозиторий с разными версиями YOLO, в Readme есть про то, как обучать: https://github.com/thtrieu/darkflow  \n","б). **Darknet** -- фреймворк на С++ c авторским YOLOv3 (от Джозефа Редмона). Можно обучить детектор, следуя инструкциям на его сайте: https://pjreddie.com/darknet/yolo/"]},{"cell_type":"code","metadata":{"id":"0P-HgE3dNvwS","colab_type":"code","colab":{}},"source":["..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WxD0FIZAhYCY","colab_type":"text"},"source":["<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"V-Gb_k8yhYCZ","colab_type":"text"},"source":["1. https://github.com/qqwweee/keras-yolo3\n","2. https://github.com/ayooshkathuria/pytorch-yolo-v3\n","3. https://github.com/eriklindernoren/PyTorch-YOLOv3\n","4. https://github.com/maiminh1996/YOLOv3-tensorflow\n","5. https://github.com/ultralytics/yolov3\n","6. https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+AnalyticsVidhya+%28Analytics+Vidhya%29"]}]}