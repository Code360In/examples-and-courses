{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[seminar]object_detection.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CMsbwW-I6xSw","colab_type":"text"},"source":["<img src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" width=500, height=450>\n","<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"yk17aKTKdKPE","colab_type":"text"},"source":["https://bit.ly/2QxD8ef"]},{"cell_type":"markdown","metadata":{"id":"AfQWiKBc6xSx","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Tx9qiCN76xSy","colab_type":"text"},"source":["<h2 style=\"text-align: center;\"><b>Детектирование объектов с помощью нейросетей</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"RpvVZo6hmGSq","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"cmCxBiUZDN5T","colab_type":"text"},"source":["<img src=\"https://rossmelbourne.com/wp-content/uploads/2018/09/Object-Detection.png\">"]},{"cell_type":"markdown","metadata":{"id":"u2pqDv3W6xS3","colab_type":"text"},"source":["<h4 style=\"text-align: center;\"><b>Составитель: Илья Захаркин (ФИВТ МФТИ, NeurusLab). По всем вопросам в Telegram: <a>@ilyazakharkin</a></b></h4>"]},{"cell_type":"markdown","metadata":{"id":"IsJ5yyjC6xS4","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"avH66iBZ6xS5","colab_type":"text"},"source":["Всем привет! Давайте узнаем, как с помощью различных нейросеток детектировать объекты на картинках. Мы рассмотрим три основные архитектуры, которые используются в detection'е: **Faster-RCNN**, **SSD** и **YOLO**. А именно, сейчас наиболее популярны **Mask-RCNN**, **SSD с MobileNet backbone'ом** и **YOLOv3**. Мы не будем слишком сильно углубляться в подробности, все полезные ссылки будут приведены в конце и по ходу ноутбука.  \n","\n","Цель этого занятия -- научить вас использовать SSD, Mask-RCNN и YOLOv3 для детектирования объектов на изображениях и заложить основу понимая того, как и почему работают детекторы."]},{"cell_type":"markdown","metadata":{"id":"a4IGr2E46xS6","colab_type":"text"},"source":["<h3 style=\"text-align: center;\"><b>Примеры</b></h3>"]},{"cell_type":"markdown","metadata":{"id":"mJ3gMHTDDa0R","colab_type":"text"},"source":["Мы хотим научиться делать примерно так:"]},{"cell_type":"markdown","metadata":{"id":"ABZ-Ydl8D9r_","colab_type":"text"},"source":["<img src=\"http://chaosmail.github.io/images/deep-learning/recognition.png\" width=450 height=300>\n","<img src=\"http://www.thesis123.com/wp-content/uploads/2018/08/C2iLN6iW8AEbk5D.jpg\" width=450 height=300>"]},{"cell_type":"markdown","metadata":{"id":"LQH1VNwKEO0m","colab_type":"text"},"source":["Кстати, Mask-RCNN и вовсе умеет детектировать объекты вместе с их масками (прямо как в фильме \"Терминатор\"!)"]},{"cell_type":"markdown","metadata":{"id":"-9Ffe8laEPOY","colab_type":"text"},"source":["<img src=\"https://i.ytimg.com/vi/OOT3UIXZztE/maxresdefault.jpg\" width=450 height=250>\n","<img src=\"https://cdn.igromania.ru/mnt/news/1/b/0/1/8/e/55545/5717f7ef43d7419e_1200xH.jpg\" width=450 height=250>"]},{"cell_type":"markdown","metadata":{"id":"1smZ1oHh6xTK","colab_type":"text"},"source":[" <h2 style=\"text-align: center;\"><b>Основная идея нейросетевых детекторов</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"_jNcyM4B6xTL","colab_type":"text"},"source":["* В *задаче классификации* мы пропускали картинку через нейросеть и получали на выходе $K$ чисел -- вероятности принадлежности к каждому из $K$ классов\n","* В *задаче сегментации* мы получали на выходе маску классов, то есть картинку $(H, W, K)$, где $K$ -- это количество классов в задаче сегментации, где каждый канал масок отвечает за один класс объектов), а $H$ и $W$ -- высота и ширина изначальной поданной на вход картинки\n","* В *задаче детектирования* мы хотим получить на выходе набор из \"прямоугольников\" (обычно их называют **bounding box**'ы, или просто **box**'ы), каждый из которых принадлежит определённому классу с некоторой вероятностью (см. картинку ниже). \n","\n","Для задачи детектирования точно так же нужно **заранее знать количество классов**, чтобы мы знали, сколько в принципе есть классов объектов. Однако остаётся другая проблема -- как узнать, скоько именно объектов на изображении? Нам ведь нужно как-то обучать нашу нейросеть, то есть подавать "]},{"cell_type":"markdown","metadata":{"id":"w_RXtz82Fglw","colab_type":"text"},"source":["<img src=\"https://cdn.cognitiveseo.com/blog/wp-content/uploads/2014/09/automatic-object-detection-images-google.jpg\" width=500 height=400>"]},{"cell_type":"markdown","metadata":{"id":"TUl08okX6xTY","colab_type":"text"},"source":["Идея в том, чтобы решать задачу регрессии при уточнении координат углов bbox'ов и одновременно решать задачу классификации внутри этих bbox'ов. Соответственно, для регрессии координат будет использовать один тип loss'а, а для классификации -- другой. Чтобы обучать нейросеть и на то, и на то, лоссы складываются с определёнными коэффициентами, но об этом позже."]},{"cell_type":"markdown","metadata":{"id":"20BPHsw-6xTZ","colab_type":"text"},"source":["**bold text**<h2 style=\"text-align: center;\"><b>Сразу в бой!</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"OwI8Xzzp6xTb","colab_type":"text"},"source":["Давайте сразу посмотрим на то, как работает детектор -- запустим его своими руками."]},{"cell_type":"markdown","metadata":{"id":"LdqwSY2h6xTc","colab_type":"text"},"source":["На данный момент код детекторов пишется преимущественно на TensorFlow, а именно -- есть такая прекрасная вещь, как TensorFlow Object Detection API: https://github.com/tensorflow/models/tree/master/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"K2Eultm86xTd","colab_type":"text"},"source":["Давайте проверим, есть ли у нас tf и его версию:"]},{"cell_type":"code","metadata":{"id":"qA0jN6j96xTe","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MiH4a6nz6xTh","colab_type":"code","outputId":"f102bb48-cb41-427d-af01-d7d7015e2ed0","executionInfo":{"status":"ok","timestamp":1558126270247,"user_tz":-180,"elapsed":1414,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.13.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PD9RZ6i86xTm","colab_type":"code","outputId":"72a2d88d-987b-49f3-c7b1-bf19d7d05d2d","executionInfo":{"status":"ok","timestamp":1558126272109,"user_tz":-180,"elapsed":3260,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":476}},"source":["from tensorflow.python.client import device_lib\n","\n","device_lib.list_local_devices()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 774020818275850614, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 3102056988981369787\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 1330617856499056129\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14800692839\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 3183762829430785852\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"z0wsfUJbkSXq","colab_type":"text"},"source":["### Краткое введение в TensorFlow"]},{"cell_type":"markdown","metadata":{"id":"EqWc0Kk5ulJK","colab_type":"text"},"source":["<img src=\"https://cdn-images-1.medium.com/max/1600/1*eFRgat2Iy6wZpi_DEItKgA.png\" width=300 height=200>"]},{"cell_type":"markdown","metadata":{"id":"zGRYtYiDkSaa","colab_type":"text"},"source":["Давайте познакомимся с TensorFlow -- очень популярным и многофункциональным фреймворком глубокого обучения."]},{"cell_type":"markdown","metadata":{"id":"Sc6aZzb8rTK2","colab_type":"text"},"source":["В TF есть две основные сущности -- это ***граф вычислений (`tf.Graph()`)*** и ***сессия (`tf.Session()`)***.\n","\n","Сначала *строится* граф вычислений, а потом в сессии он *исполняется*.\n","\n","Пример графа вычислений (очень условный):"]},{"cell_type":"markdown","metadata":{"id":"w_ZolFY9rQRC","colab_type":"text"},"source":["<img src=\"https://camo.qiitausercontent.com/137bc298bf30fe06e61b59a638fea966d272f2b8/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f313034362f38663430386438392d666563362d643761632d633961662d3865393061383039613233622e706e67\" width=300 height=400>"]},{"cell_type":"markdown","metadata":{"id":"fadCHOsIr4dr","colab_type":"text"},"source":["А вот пример реального графа (скрин из TensorBoard):"]},{"cell_type":"markdown","metadata":{"id":"qqgD3gjJr4gR","colab_type":"text"},"source":["<img src=\"https://blog.altoros.com/wp-content/uploads/2016/05/visualizing-graphs-with-tensorboard-wxb-group.png\">"]},{"cell_type":"markdown","metadata":{"id":"_fQbrYvauxV-","colab_type":"text"},"source":["То есть граф -- то нечто построенное нами до сессии, а сессия -- это то, во время чего все операции в графе исполняются (при подаче в него входных данных). Пока что это всё, что нам нужно знать, чтобы понять код для запуска детектора из TF ObjDet API."]},{"cell_type":"markdown","metadata":{"id":"TMynA4vskSd2","colab_type":"text"},"source":["КРАЙНЕ советую пройти самостоятельно следующие мини-курсы по TF:\n","* Начать с официального intro: https://www.tensorflow.org/guide/low_level_intro \n","* Продолжить этими замечательными практикумами: https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd\n","* Посмотреть что-то здесь, если не очень понятно: https://github.com/Hvass-Labs/TensorFlow-Tutorials\n","* Закончить продвинутым курсом: https://github.com/sjchoi86/advanced-tensorflow\n","\n","И не забудьте заглянуть в официальные туториалы: https://www.tensorflow.org/tutorials/"]},{"cell_type":"markdown","metadata":{"id":"ycD9kX6DkSjv","colab_type":"text"},"source":["Это будет очень и очень полезно, если вы собираетесь заниматься deep learning'ом в \"реальной жизни\", уметь читать сложный код и прокачиваться в нейросетках."]},{"cell_type":"markdown","metadata":{"id":"dUbgpr5h7QA5","colab_type":"text"},"source":["[Установим TF ObjDet API на Google Colab](https://stackoverflow.com/questions/48663207/colaboratory-install-tensorflow-object-detection-api):"]},{"cell_type":"code","metadata":{"id":"e04gZj816xTr","colab_type":"code","outputId":"534f3ef9-c311-429b-abc4-5e7986356fc9","executionInfo":{"status":"ok","timestamp":1558126296105,"user_tz":-180,"elapsed":27247,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":1649}},"source":["!apt-get install -y -qq protobuf-compiler python-pil python-lxml\n","!pip install --user Cython\n","!pip install --user contextlib2\n","!pip install --user jupyter\n","!pip install --user matplotlib"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package python-bs4.\n","(Reading database ... 130824 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Setting up python-pil:amd64 (5.1.0-1) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.7)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (0.5.5)\n","Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.4.4)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.6.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.2)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.4.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (6.0.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.5.0)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (4.3.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (4.4.0)\n","Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (5.2.4)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (2.1.3)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (0.2.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (4.5.3)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (5.5.0)\n","Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (4.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (2.10.1)\n","Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.4.2)\n","Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n","\u001b[K     |████████████████████████████████| 337kB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.2)\n","Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter) (1.12.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets->qtconsole->jupyter) (4.4.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter) (17.0.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter) (2.5.3)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.7.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (41.0.1)\n","Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter) (0.6.0)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->jupyter) (2.6.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter) (1.1.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter) (0.1.7)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n","\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n","Installing collected packages: prompt-toolkit\n","Successfully installed prompt-toolkit-2.0.9\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["prompt_toolkit"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n","Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dw_DAdDI6xTu","colab_type":"code","colab":{}},"source":["!git clone --quiet https://github.com/tensorflow/models.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZkGcpT96xTx","colab_type":"code","outputId":"7320a14c-868f-4d54-9cfb-cc3e6a5c08e8","executionInfo":{"status":"ok","timestamp":1558126320725,"user_tz":-180,"elapsed":51848,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["models\tsample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ABAGvzON6xTz","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('models/research')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yT4n0BoMCWQl","colab_type":"code","outputId":"a84b88bd-c87f-45c4-8c80-3e56c864cda2","executionInfo":{"status":"ok","timestamp":1558126322982,"user_tz":-180,"elapsed":54079,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":612}},"source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["a3c_blogpost\t\t\t  lm_commonsense\n","adversarial_crypto\t\t  lstm_object_detection\n","adversarial_logit_pairing\t  marco\n","adversarial_text\t\t  maskgan\n","adv_imagenet_models\t\t  minigo\n","astronet\t\t\t  morph_net\n","attention_ocr\t\t\t  namignizer\n","audioset\t\t\t  neural_gpu\n","autoaugment\t\t\t  neural_programmer\n","autoencoder\t\t\t  next_frame_prediction\n","brain_coder\t\t\t  nst_blogpost\n","cognitive_mapping_and_planning\t  object_detection\n","cognitive_planning\t\t  pcl_rl\n","compression\t\t\t  ptn\n","cvt_text\t\t\t  qa_kg\n","deep_contextual_bandits\t\t  README.md\n","deeplab\t\t\t\t  real_nvp\n","deep_speech\t\t\t  rebar\n","delf\t\t\t\t  resnet\n","differential_privacy\t\t  sentiment_analysis\n","domain_adaptation\t\t  seq2species\n","efficient-hrl\t\t\t  setup.py\n","feelvos\t\t\t\t  skip_thoughts\n","fivo\t\t\t\t  slim\n","gan\t\t\t\t  steve\n","global_objectives\t\t  street\n","im2txt\t\t\t\t  struct2depth\n","inception\t\t\t  swivel\n","keypointnet\t\t\t  syntaxnet\n","learned_optimizer\t\t  tcn\n","learning_to_remember_rare_events  tensorrt\n","learning_unsupervised_learning\t  textsum\n","lexnet_nc\t\t\t  transformer\n","lfads\t\t\t\t  vid2depth\n","lm_1b\t\t\t\t  video_prediction\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lED2dG-08Gk-","colab_type":"code","colab":{}},"source":["!protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKEUbZDG8Gni","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append('/content/models/research/slim')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pV19JmcR02FA","colab_type":"code","outputId":"dbce43b6-c35f-4e8f-bcf2-84ebf5c5ee0e","executionInfo":{"status":"ok","timestamp":1558126325824,"user_tz":-180,"elapsed":56884,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pylab inline"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lY7GfdJS8GtB","colab_type":"code","outputId":"2ee80a42-e786-4f98-967e-1e35531799d6","executionInfo":{"status":"error","timestamp":1558126329227,"user_tz":-180,"elapsed":60278,"user":{"displayName":"Александр Олегович Казаков","photoUrl":"","userId":"00367260076017097115"}},"colab":{"base_uri":"https://localhost:8080/","height":544}},"source":["%run object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["..."],"name":"stderr"},{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":[".........s...\n","----------------------------------------------------------------------\n","Ran 16 tests in 0.108s\n","\n","OK (skipped=1)\n"],"name":"stderr"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-31812fc4de3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run object_detection/builders/model_builder_test.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-58>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                         \u001b[0;31m# regular execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'i'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    726\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                             runner(filename, prog_ns, prog_ns,\n\u001b[0;32m--> 728\u001b[0;31m                                     exit_ignore=exit_ignore)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m't'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mmpl_execfile\u001b[0;34m(fname, *where, **kw)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# make rendering call now, if the user tried to do it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_if_interactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'called'"]}]},{"cell_type":"markdown","metadata":{"id":"xBMMGQ0TCHF9","colab_type":"text"},"source":["Давайте воспроизведём их туториал:"]},{"cell_type":"code","metadata":{"id":"vDvRfv8QCahG","colab_type":"code","colab":{}},"source":["os.chdir('./object_detection')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nOXE0xRKCysI","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s7RLuw9_mt3z","colab_type":"text"},"source":["https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb"]},{"cell_type":"code","metadata":{"id":"CLMiOpYpCGVR","colab_type":"code","colab":{}},"source":["import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from distutils.version import StrictVersion\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed since the notebook is stored in the object_detection folder.\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","if StrictVersion(tf.__version__) < StrictVersion('1.9.0'):\n","    raise ImportError('Please upgrade your TensorFlow installation to v1.9.* or later!')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCpwreKy9x48","colab_type":"code","colab":{}},"source":["# This is needed to display the images.\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mI4aApMwCae3","colab_type":"code","colab":{}},"source":["from utils import label_map_util\n","from utils import visualization_utils as vis_util"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3i713yBoTF9","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1S0FS8E-HvpK","colab_type":"text"},"source":["Загрузим модель-детектор. В данном случае это *Single Shot Multibox (SSD)* детектор с *MobileNetV1* в качестве backbone-нейросети (*backbone*-нейросеть -- обычно так называют нейросеть, которой извлекают фичи из картинки), и этот детектор был обучен на *MS COCO (2017)* датасете."]},{"cell_type":"code","metadata":{"id":"W1s_2Zmr9x7d","colab_type":"code","colab":{}},"source":["# What model to download.\n","MODEL_NAME = 'ssd_mobilenet_v1_coco_2018_01_28'\n","MODEL_FILE = MODEL_NAME + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CpiX7arYDA2J","colab_type":"code","colab":{}},"source":["opener = urllib.request.URLopener()\n","opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar_file = tarfile.open(MODEL_FILE)\n","\n","for file in tar_file.getmembers():\n","    file_name = os.path.basename(file.name)\n","    if 'frozen_inference_graph.pb' in file_name:\n","        tar_file.extract(file, os.getcwd())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g78XfSZUNQti","colab_type":"text"},"source":["Загрузим замороженную модель в память:"]},{"cell_type":"code","metadata":{"id":"0CIGMNMcDA4k","colab_type":"code","colab":{}},"source":["detection_graph = tf.Graph()\n","\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hnFDe5aXN0eG","colab_type":"text"},"source":["Загрузим словарь, который будет говорить, какому классу будет сответствовать предсказанная метка:"]},{"cell_type":"code","metadata":{"id":"rPZdYuyJ9x9w","colab_type":"code","colab":{}},"source":["category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EXKHNW8CN0TO","colab_type":"text"},"source":["Всопмогательная функция для создания `np.array` из `PIL.Image`:"]},{"cell_type":"code","metadata":{"id":"tjMmCO4nN9bC","colab_type":"code","colab":{}},"source":["def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ulft-1_xN0Zq","colab_type":"text"},"source":["Зададим путь к изображениям:"]},{"cell_type":"code","metadata":{"id":"zVPjn-ZQgN80","colab_type":"code","colab":{}},"source":["#!wget https://www.polytechnique.edu/sites/all/institutionnel/mipt.jpg\n","#!mv mipt.jpg ./test_images/image4.jpg"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFWNGJk9OrAy","colab_type":"code","colab":{}},"source":["# For the sake of simplicity we will use only 2 images:\n","# image1.jpg\n","# image2.jpg\n","# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","PATH_TO_TEST_IMAGES_DIR = 'test_images'\n","TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 4) ]\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfsBF_3cOrT-","colab_type":"text"},"source":["Функция для загрузки графа и прогона через него картинки:"]},{"cell_type":"code","metadata":{"id":"gNdboClyOrHf","colab_type":"code","colab":{}},"source":["def run_inference_for_single_image(image, graph):\n","    \n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Get handles to input and output tensors\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {output.name for op in ops for output in op.outputs}\n","            \n","            tensor_dict = {}\n","            for key in ['num_detections', 'detection_boxes', 'detection_scores',\n","                        'detection_classes', 'detection_masks']:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n","                    \n","            if 'detection_masks' in tensor_dict:\n","                # The following processing is only for single image\n","                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n","                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n","                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Follow the convention by adding back the batch dimension\n","                tensor_dict['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n","            \n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,\n","                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # all outputs are float32 numpy arrays, so convert types as appropriate\n","            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            \n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","            \n","    return output_dict"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PG1SyChiOrWN","colab_type":"text"},"source":["Время сделать главное -- предсказать детекции на картинке:"]},{"cell_type":"code","metadata":{"id":"47HNdqrFOrMI","colab_type":"code","colab":{}},"source":["for image_path in TEST_IMAGE_PATHS:\n","    \n","    image = Image.open(image_path)\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = load_image_into_numpy_array(image)\n","    print(image_np.shape)\n","    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","    image_np_expanded = np.expand_dims(image_np, axis=0)\n","    \n","    # Actual detection\n","    output_dict = run_inference_for_single_image(image_np, detection_graph)\n","    \n","    # Visualization of the results of a detection\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","      image_np,\n","      output_dict['detection_boxes'],\n","      output_dict['detection_classes'],\n","      output_dict['detection_scores'],\n","      category_index,\n","      instance_masks=output_dict.get('detection_masks'),\n","      use_normalized_coordinates=True,\n","      line_thickness=8)\n","    \n","    plt.figure(figsize=IMAGE_SIZE)\n","    plt.imshow(image_np)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9xZkSWipyivL","colab_type":"code","colab":{}},"source":["!pwd "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z4YbLb7x1UAt","colab_type":"text"},"source":["На самом деле, TensorFlow -- это не только библиотека для написания нейросетей, есть ещё много модулей для самых разных целей, а именно:"]},{"cell_type":"markdown","metadata":{"id":"ew1vm2mEqMt1","colab_type":"text"},"source":["* [TensorFlow.js](https://js.tensorflow.org/) -- использование нейронок в браузере\n","* [TensorFlow Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) -- много готовых слоёв и кода, который делает обучение сеток более удобным и быстрым процессом\n","* [TensorFlow Serving](https://www.tensorflow.org/serving/) -- модуль, чтобы удобнее было выводить свои нейронки в продакшн (деплоить их)\n","* [TensorFlow Hub](https://www.tensorflow.org/hub/) -- хранилище готовых моделей\n","* [TensorFlow Lite](https://www.tensorflow.org/lite/) -- чтобы творить deep learning на мобильных устройствах"]},{"cell_type":"markdown","metadata":{"id":"pG6IzoW81L1l","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"2utqlCGbOrY3","colab_type":"text"},"source":["Отлично, мы научились детектировать объекты с TF Object Detection API, НО - - если Вы попробуете просто указать вместо текущей модели какое-то другое имя из зоопарка детекторов, то он выдаст ошибку. Как её избежать? "]},{"cell_type":"markdown","metadata":{"id":"iSP7ol9_02kW","colab_type":"text"},"source":["### Mask R-CNN"]},{"cell_type":"markdown","metadata":{"id":"f0TwCif705f5","colab_type":"text"},"source":["Mask R-CNN можно так же запустить из TF Object Detection API. Давайте сделаем это!"]},{"cell_type":"markdown","metadata":{"id":"b6DWXERBG7z_","colab_type":"text"},"source":["https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md"]},{"cell_type":"code","metadata":{"id":"DBZopJ4iovTU","colab_type":"code","colab":{}},"source":["# !wget http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_EkjwZg0sHI","colab_type":"text"},"source":["Ещё хорошая реализация Mask R-CNN на Keras есть в [этом репозитоии](https://github.com/matterport/Mask_RCNN)"]},{"cell_type":"markdown","metadata":{"id":"YgA-d3nq0sOI","colab_type":"text"},"source":["### YOLOv3"]},{"cell_type":"markdown","metadata":{"id":"hyQcdfD40sQo","colab_type":"text"},"source":["Осталось научиться запускать YOLOv3, и тогда можно считать, что мы победили."]},{"cell_type":"markdown","metadata":{"id":"h-iEnWL8wC3v","colab_type":"text"},"source":["Один из гитхабов с реализацией YOLOv3: https://github.com/ayooshkathuria/pytorch-yolo-v3"]},{"cell_type":"code","metadata":{"id":"4PsXgF2DFarH","colab_type":"code","colab":{}},"source":["В домашнем задании!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJwzY4r53O3y","colab_type":"text"},"source":["Ещё хорошие варианты: https://github.com/akozd/tensorflow_yolo_v3 и https://github.com/maiminh1996/YOLOv3-tensorflow "]},{"cell_type":"markdown","metadata":{"id":"aQAyB0DwwC6S","colab_type":"text"},"source":["### Полезные ссылки"]},{"cell_type":"markdown","metadata":{"id":"vY5MPbbB2bmG","colab_type":"text"},"source":["#### Введение\n","\n","Отличная статья-введение в object detection: https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852\n","\n","#### Данные\n","\n","PASCAL VOC датасет: http://host.robots.ox.ac.uk/pascal/VOC/ \n","\n","MS COCO датасет: http://cocodataset.org/#home\n","\n","Скрипт для перевода разметки на VOC в разметку на COCO: https://github.com/soumenpramanik/Convert-Pascal-VOC-to-COCO/blob/master/convertVOC2COCO.py\n","\n","Google Open Images датасет: https://storage.googleapis.com/openimages/web/index.html\n","\n","EPIC Kithens: https://epic-kitchens.github.io/2018\n","\n","Датасет для детектирования и сегментации типов одежды: https://github.com/eBay/modanet\n","\n","#### Списки\n","\n","Исчерпывающий список нейросетевых детекторов с их кодом: https://github.com/amusi/awesome-object-detection\n","\n","#### Сравнение детекторов друг с другом\n","\n","Статья про сравнение нейросетевых детекторов: https://arxiv.org/pdf/1611.10012.pdf \n","\n","#### YOLOv3\n","\n","Сайт разработчика YOLO: https://pjreddie.com/darknet/yolo/\n","\n","Статьи: [YOLO](), [YOLOv2](), [YOLOv3]()\n","\n","Туториал по написанию своего YOLOv3: https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/\n","\n","Русскоязычная статья на Хабре: https://habr.com/company/dataart/blog/350120/\n","\n","#### Single Shot Multibox Detector (SSD)\n","\n","Статья: https://arxiv.org/abs/1512.02325\n","\n","[Статья-туториал](https://medium.com/@jonathan_hui/ssd-object-detection-single-shot-multibox-detector-for-real-time-processing-9bd8deac0e06)\n","\n","Реализация на PyTorch: https://github.com/amdegroot/ssd.pytorch\n","\n","Реализация на Keras: https://github.com/rykov8/ssd_keras\n","\n","#### Faster-RCNN\n","\n","Статья: https://arxiv.org/pdf/1506.01497.pdf\n","\n","Реализация на PyTorch: https://github.com/jwyang/faster-rcnn.pytorch\n","\n","#### Tensorflow Object Detection API\n","\n","Главный репозиторий: https://github.com/tensorflow/models/tree/master/research/object_detection\n","\n","Запуск на Windows: https://medium.com/@rohitrpatil/how-to-use-tensorflow-object-detection-api-on-windows-102ec8097699\n","\n","#### Объяснение метрики mAP\n","\n","Раз: https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173\n","\n","Два: https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173\n","\n","#### Соревнования\n","\n","2-ое место на Google Open Images датасете: https://arxiv.org/abs/1809.00778 \n","\n","#### Ещё\n","\n","Object Detection с помощью OpenCV: https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/\n","\n","Реализации *-RCNN от Facebook (на Caffe): https://github.com/facebookresearch/Detectron\n","\n","Реализации детекторов на PyTorch: https://github.com/ignacio-rocco/detectorch\n","\n","Инструмент для разметки боксов: https://github.com/tzutalin/labelImg\n","\n"]}]}